{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Likelihood Function**\n",
    "\n",
    "- likelihood 수식\n",
    "    $$ L(\\theta|X) $$\n",
    "    - $ \\theta $ 는 모수(**분포의 형태와 특성** 나타냄)\n",
    "    - $ X $ 는 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Binary Cross-Entropy (BCE)**\n",
    "- 최대우도추정(MLE)에서 유도될 수 있다.\n",
    "- 조건 : 이진 분류의 클래스 $y_i \\in \\{0,1\\}$\n",
    "- 확률 :\n",
    "   - 클래스가 1 일 확율 $= \\hat{y}$\n",
    "   - 클래스가 0 일 확율 $= 1 - \\hat{y}$\n",
    "   > **예시**<br>\n",
    "   > 클래스 1 이 나올확률이 40% 일때 $\\hat{y} = 0.4$ <Br>\n",
    "   > 클래스 0 이 나올확률 $= 1 - \\hat{y} = 0.6$\n",
    "\n",
    "- **우도(likelihood)**:\n",
    "   - 관측된 실제 결과를 예측할 확률.\n",
    "   - $y_i = 1$ 인 경우\n",
    "      - 모델이 $x_i$에 대해 $\\hat{y}_i$의 확률로 클래스 1을 예측한 것이므로 우도는 $\\hat{y}_i$\n",
    "   - $y_i = 0$ 인 경우\n",
    "      - 모델이 $x_i$에 대해 $1-\\hat{y}_i$의 확률로 클래스 0을 예측한 것이므로 우도는 $1-\\hat{y}_i$\n",
    "   - **결합 우도**\n",
    "      $$(\\hat{y}_i)^{y_i} (1-\\hat{y}_i)^{1-y_i}$$\n",
    "      - $y$ 에 1 을 대입 하면 $\\hat{y}_i$\n",
    "      - $y$ 에 0 을 대입 하면 $1-\\hat{y}_i$ 가 나오는 함수식\n",
    "   - **전체 데이터에 대한 결합 우도 함수**\n",
    "      $$L(\\theta | X) = \\prod_{i=1}^{n} (\\hat{y}_i)^{y_i} (1-\\hat{y}_i)^{1-y_i}$$\n",
    "\n",
    "- **로그 우도(log-likelihood)**:\n",
    "   $$ \\log L = \\sum_{i=1}^{n} \\left[ y_i \\log(\\hat{y}_i) + (1-y_i) \\log(1-\\hat{y}_i) \\right] $$\n",
    "   - 여기서, $L$은 전체 데이터셋에 대한 결합 우도\n",
    "\n",
    "- **최대우도추정**:\n",
    "   - $-\\log L$ 사용\n",
    "     $$\n",
    "     -\\log L = -\\sum_{i=1}^{n} \\left[ y_i \\log(\\hat{y}_i) + (1-y_i) \\log(1-\\hat{y}_i) \\right]\n",
    "     $$\n",
    "\n",
    "- **평균을 내어 손실 함수 정의**:\n",
    "   - 각 데이터 포인트에 대한 손실의 평균으로 BCE 손실 함수 정의:\n",
    "     $$\n",
    "     \\text{BCE} = -\\frac{1}{n} \\sum_{i=1}^{n} \\left[ y_i \\log(\\hat{y}_i) + (1-y_i) \\log(1-\\hat{y}_i) \\right]\n",
    "     $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Categorical Cross-Entropy(CCE)**\n",
    "- $x_i$가 실제로 레이블 $y_i = c$를 가지는 경우\n",
    "- 모델이 예측한 확률이 $\\hat{y}_{i,c}$일 때, $x_i$에 대한 우도는 $\\hat{y}_{i,c}$입니다.\n",
    "\n",
    "- **우도**\n",
    "    $$\\text{likelihood} = \\hat{y}_{i,c}$$\n",
    "  - $y_i$가 클래스 $c$인 경우\n",
    "\n",
    "- **결합 우도 함수**\n",
    "  - 데이터셋의 모든 샘플에 대하여 결합 우도\n",
    "  $$ L(\\theta | X) = \\prod_{i=1}^{n} \\prod_{c=1}^{C} (\\hat{y}_{i,c})^{y_{i,c}} $$\n",
    "  - $y_{i,c}$는 샘플 $i$의 실제 클래스 $c$에 대한 원-핫 인코딩(one-hot encoding) 값\n",
    "  - 여기서 라벨 수가 많아지면 너무 sparse 하기 때문에 **SCCE(Sparse Categroical Cross Entropy)** 를 이용한다.\n",
    "    - -> 정수 라벨을 이용\n",
    "  - $y_{i,c} = 1$이면 샘플 $i$가 클래스 $c$에 속함을 의미합니다.\n",
    "\n",
    "- **로그 우도(log-likelihood)**\n",
    "  $$ \\log L = \\sum_{i=1}^{n} \\sum_{c=1}^{C} y_{i,c} \\log(\\hat{y}_{i,c}) $$\n",
    "\n",
    "- **손실 함수 최소화**\n",
    "  - 손실 함수를 최소화하기 위해 로그 우도의 음수를 취함\n",
    "  $$-\\log L = -\\sum_{i=1}^{n} \\sum_{c=1}^{C} y_{i,c} \\log(\\hat{y}_{i,c})$$\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
