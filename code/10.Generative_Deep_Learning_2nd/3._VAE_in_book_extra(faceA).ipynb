{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# GPU 디바이스를 자동으로 인식하고 사용합니다.\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)  # GPU 메모리 동적 할당 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "size = 32\n",
    "\n",
    "train_data = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"C:\\\\Users\\\\crazy\\\\Downloads\\\\archive\\\\img_align_celeba\\\\picted\",\n",
    "    labels=None,\n",
    "    color_mode=\"rgb\",\n",
    "    image_size=(size, size),\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    interpolation=\"bilinear\"  # 수정된 부분\n",
    ")\n",
    "\n",
    "def preprocess(img):\n",
    "    img = tf.cast(img, \"float32\") / 255.0\n",
    "    return img\n",
    "\n",
    "train = train_data.map(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for images in train:\n",
    "#     plt.imshow(images[0].numpy().astype(\"uint8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vae\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder (Functional)        [(None, 1),               1478146   \n",
      "                              (None, 1),                         \n",
      "                              (None, 1)]                         \n",
      "                                                                 \n",
      " model (Functional)          (None, 32, 32, 1)         5707265   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,185,417\n",
      "Trainable params: 7,182,339\n",
      "Non-trainable params: 3,078\n",
      "_________________________________________________________________\n",
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 16, 16, 128)  98432       ['encoder_input[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 16, 16, 128)  512        ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 16, 16, 128)  0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 8, 8, 128)    1048704     ['leaky_re_lu[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 8, 8, 128)   512         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 8, 8, 128)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 4, 4, 128)    262272      ['leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 4, 4, 128)   512         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 4, 4, 128)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 2, 2, 128)    65664       ['leaky_re_lu_2[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 2, 2, 128)   512         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)      (None, 2, 2, 128)    0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 512)          0           ['leaky_re_lu_3[0][0]']          \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 1)            513         ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 1)            513         ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " sampling (Sampling)            (None, 1)            0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,478,146\n",
      "Trainable params: 1,477,122\n",
      "Non-trainable params: 1,024\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " decoder_input (InputLayer)  [(None, 1)]               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1024      \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 512)               0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 2, 2, 128)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 4, 4, 128)        65664     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 4, 4, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 8, 8, 128)        262272    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 8, 8, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 16, 16, 128)      1048704   \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 16, 16, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 32, 32, 128)      4194432   \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 32, 32, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2DT  (None, 32, 32, 1)        131073    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,707,265\n",
      "Trainable params: 5,705,217\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras = tf.keras\n",
    "K = tf.keras.backend\n",
    "\n",
    "class Sampling(keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = K.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "#인코더 부분\n",
    "encoder_input = keras.layers.Input(shape=(size, size, 3), name=\"encoder_input\")\n",
    "\n",
    "x = keras.layers.Conv2D(128, (16, 16), strides=2, padding=\"same\")(encoder_input)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "x = keras.layers.Conv2D(128, (8, 8), strides=2, padding=\"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "x = keras.layers.Conv2D(128, (4, 4), strides=2, padding=\"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "x = keras.layers.Conv2D(128, (2, 2), strides=2, padding=\"same\")(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "shape_before_flattening = K.int_shape(x)[1:]\n",
    "x = keras.layers.Flatten()(x)\n",
    "\n",
    "z_mean = keras.layers.Dense(1, name=\"z_mean\")(x)\n",
    "z_log_var = keras.layers.Dense(1, name=\"z_log_var\")(x)\n",
    "\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.models.Model(encoder_input, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "\n",
    "#디코더 부분\n",
    "decoder_input = keras.layers.Input(shape=(1,), name=\"decoder_input\")\n",
    "x = keras.layers.Dense(np.prod(shape_before_flattening))(decoder_input)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "x = keras.layers.Reshape(shape_before_flattening)(x)\n",
    "\n",
    "x = keras.layers.Conv2DTranspose(128, (2, 2), strides=2, padding=\"same\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "x = keras.layers.Conv2DTranspose(128, (4, 4), strides=2, padding=\"same\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "x = keras.layers.Conv2DTranspose(128, (8, 8), strides=2, padding=\"same\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "x = keras.layers.Conv2DTranspose(128, (16, 16), strides=2, padding=\"same\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "decoder_output = keras.layers.Conv2DTranspose(1, (size, size), strides=1, padding=\"same\")(x)\n",
    "\n",
    "decoder = keras.models.Model(decoder_input, decoder_output)\n",
    "\n",
    "\n",
    "class VAE(keras.models.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "        #loss 값을 모니터링 하는 요소\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name='total_loss')\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "    \n",
    "    def call(self, input):\n",
    "        z_mean, z_log_var, z = encoder(input)\n",
    "        reconstruction = decoder(z)\n",
    "        return z_mean, z_log_var, reconstruction\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, reconstruction = self(data)\n",
    "            reconstruction_loss = tf.reduce_mean( 500 * tf.losses.binary_crossentropy(data, reconstruction, axis=(1,2,3)))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum( 0.6 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)), axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.build(input_shape=(None, size, size, 3))\n",
    "vae.compile(optimizer=\"adam\")\n",
    "vae.summary()\n",
    "\n",
    "encoder.summary()\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 1s/step - total_loss: nan - reconstruction_loss: nan - kl_loss: nan\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 83ms/step - total_loss: nan - reconstruction_loss: nan - kl_loss: nan\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 73ms/step - total_loss: nan - reconstruction_loss: nan - kl_loss: nan\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 52ms/step - total_loss: nan - reconstruction_loss: nan - kl_loss: nan\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 52ms/step - total_loss: nan - reconstruction_loss: nan - kl_loss: nan\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 49ms/step - total_loss: nan - reconstruction_loss: nan - kl_loss: nan\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 51ms/step - total_loss: nan - reconstruction_loss: nan - kl_loss: nan\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 52ms/step - total_loss: nan - reconstruction_loss: nan - kl_loss: nan\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 52ms/step - total_loss: nan - reconstruction_loss: nan - kl_loss: nan\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 53ms/step - total_loss: nan - reconstruction_loss: nan - kl_loss: nan\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32, name='encoder_input'), name='encoder_input', description=\"created by layer 'encoder_input'\"), but it was called on an input with incompatible shape (None,).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\crazy\\OneDrive\\Desktop\\Latent Diffusion\\.conda\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\crazy\\OneDrive\\Desktop\\Latent Diffusion\\.conda\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\crazy\\OneDrive\\Desktop\\Latent Diffusion\\.conda\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\crazy\\OneDrive\\Desktop\\Latent Diffusion\\.conda\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\crazy\\OneDrive\\Desktop\\Latent Diffusion\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\crazy\\AppData\\Local\\Temp\\__autograph_generated_filepnzw9gfv.py\", line 10, in tf__call\n        (z_mean, z_log_var, z) = ag__.converted_call(ag__.ld(encoder), (ag__.ld(input),), None, fscope)\n\n    ValueError: Exception encountered when calling layer \"vae_2\" \"                 f\"(type VAE).\n    \n    in user code:\n    \n        File \"C:\\Users\\crazy\\AppData\\Local\\Temp\\ipykernel_15828\\4215938357.py\", line 89, in call  *\n            z_mean, z_log_var, z = encoder(input)\n        File \"c:\\Users\\crazy\\OneDrive\\Desktop\\Latent Diffusion\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"c:\\Users\\crazy\\OneDrive\\Desktop\\Latent Diffusion\\.conda\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 250, in assert_input_compatibility\n            raise ValueError(\n    \n        ValueError: Exception encountered when calling layer \"encoder\" \"                 f\"(type Functional).\n        \n        Input 0 of layer \"conv2d\" is incompatible with the layer: expected min_ndim=4, found ndim=1. Full shape received: (None,)\n        \n        Call arguments received by layer \"encoder\" \"                 f\"(type Functional):\n          • inputs=tf.Tensor(shape=(None,), dtype=int32)\n          • training=False\n          • mask=None\n    \n    \n    Call arguments received by layer \"vae_2\" \"                 f\"(type VAE):\n      • input=tf.Tensor(shape=(None,), dtype=int32)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\crazy\\OneDrive\\Desktop\\Latent Diffusion\\3. VAE in book extra(faceA).ipynb 셀 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/crazy/OneDrive/Desktop/Latent%20Diffusion/3.%20VAE%20in%20book%20extra%28faceA%29.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m vae\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39moptimizer)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/crazy/OneDrive/Desktop/Latent%20Diffusion/3.%20VAE%20in%20book%20extra%28faceA%29.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m vae\u001b[39m.\u001b[39mfit(train, epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, batch_size\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/crazy/OneDrive/Desktop/Latent%20Diffusion/3.%20VAE%20in%20book%20extra%28faceA%29.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m vae\u001b[39m.\u001b[39;49mpredict([\u001b[39m1\u001b[39;49m])\n",
      "File \u001b[1;32mc:\\Users\\crazy\\OneDrive\\Desktop\\Latent Diffusion\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filea4ipytsn.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filepnzw9gfv.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m      8\u001b[0m do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m      9\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m---> 10\u001b[0m (z_mean, z_log_var, z) \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(encoder), (ag__\u001b[39m.\u001b[39;49mld(\u001b[39minput\u001b[39;49m),), \u001b[39mNone\u001b[39;49;00m, fscope)\n\u001b[0;32m     11\u001b[0m reconstruction \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(decoder), (ag__\u001b[39m.\u001b[39mld(z),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     12\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\crazy\\OneDrive\\Desktop\\Latent Diffusion\\.conda\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\crazy\\OneDrive\\Desktop\\Latent Diffusion\\.conda\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\crazy\\OneDrive\\Desktop\\Latent Diffusion\\.conda\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\crazy\\OneDrive\\Desktop\\Latent Diffusion\\.conda\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\crazy\\OneDrive\\Desktop\\Latent Diffusion\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\crazy\\AppData\\Local\\Temp\\__autograph_generated_filepnzw9gfv.py\", line 10, in tf__call\n        (z_mean, z_log_var, z) = ag__.converted_call(ag__.ld(encoder), (ag__.ld(input),), None, fscope)\n\n    ValueError: Exception encountered when calling layer \"vae_2\" \"                 f\"(type VAE).\n    \n    in user code:\n    \n        File \"C:\\Users\\crazy\\AppData\\Local\\Temp\\ipykernel_15828\\4215938357.py\", line 89, in call  *\n            z_mean, z_log_var, z = encoder(input)\n        File \"c:\\Users\\crazy\\OneDrive\\Desktop\\Latent Diffusion\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"c:\\Users\\crazy\\OneDrive\\Desktop\\Latent Diffusion\\.conda\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 250, in assert_input_compatibility\n            raise ValueError(\n    \n        ValueError: Exception encountered when calling layer \"encoder\" \"                 f\"(type Functional).\n        \n        Input 0 of layer \"conv2d\" is incompatible with the layer: expected min_ndim=4, found ndim=1. Full shape received: (None,)\n        \n        Call arguments received by layer \"encoder\" \"                 f\"(type Functional):\n          • inputs=tf.Tensor(shape=(None,), dtype=int32)\n          • training=False\n          • mask=None\n    \n    \n    Call arguments received by layer \"vae_2\" \"                 f\"(type VAE):\n      • input=tf.Tensor(shape=(None,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#모델 새로 정의\n",
    "vae = VAE(encoder, decoder)\n",
    "\n",
    "\n",
    "#모델 훈련하기\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "vae.compile(optimizer=optimizer)\n",
    "vae.fit(train, epochs=10, batch_size=10)\n",
    "\n",
    "vae.predict([1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
