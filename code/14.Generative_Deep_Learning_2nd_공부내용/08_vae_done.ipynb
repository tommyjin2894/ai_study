{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# GPU 디바이스 목록 가져오기\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    print(\"사용 가능한 GPU 디바이스:\")\n",
    "    for gpu in gpus:\n",
    "        print(\"디바이스 이름:\", gpu.name)\n",
    "else:\n",
    "    print(\"사용 가능한 GPU 디바이스가 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 전처리 코드\n",
    "\n",
    "# image_dir = \"C:\\\\Users\\\\crazy\\\\Downloads\\\\archive\\\\img_align_celeba\\\\img_align_celeba\"\n",
    "# image_dir = \"C:\\\\Users\\\\crazy\\\\Downloads\\\\archive\\\\img_align_celeba\\\\10000\"\n",
    "# image_dir = \"C:\\\\Users\\\\crazy\\\\Downloads\\\\archive\\\\img_align_celeba\\\\10\"\n",
    "# image_dir = \"C:\\\\Myfolder\\\\AI_tools\\\\dfl\\\\df_NVIDIA_RTX3000_series\\\\workspace\\\\data_src\\\\aligned\"\n",
    "# image_dir = \"C:\\\\Myfolder\\\\AI_tools\\\\sd.webui\\\\this\\\\fun\\\\image\"\n",
    "# image_dir = \"C:\\\\Users\\\\crazy\\Downloads\\\\archive\\\\img_align_celeba\\\\facesetav\"\n",
    "image_dir = \"C:\\\\Users\\\\crazy\\Downloads\\\\archive\\\\img_align_celeba\\\\picted\"\n",
    "# crop_width, crop_height = 1024, 1024  # 자를 크기\n",
    "resize_width, resize_height = 128, 128  # 변경할 크기\n",
    "\n",
    "# 이미지 목록 가져오기\n",
    "image_files = os.listdir(image_dir)\n",
    "\n",
    "# 이미지를 NumPy 배열로 로드하고 크기 변경하기\n",
    "images = []\n",
    "for filename in image_files:\n",
    "    img = tf.keras.preprocessing.image.load_img(os.path.join(image_dir, filename), target_size=(resize_width, resize_height))\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img = img / 255.0  # 이미지 정규화\n",
    "    images.append(img)\n",
    "images = np.array(images)\n",
    "\n",
    "\n",
    "# 이미지 중에서 무작위로 하나 선택\n",
    "random_index = random.randint(0, len(images) - 1)\n",
    "selected_image = images[random_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 선택한 이미지 표시\n",
    "# plt.imshow(selected_image)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras = tf.keras\n",
    "K = tf.keras.backend\n",
    "\n",
    "class Sampling(keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = K.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "#인코더 부분\n",
    "encoder_input = keras.layers.Input(shape=(resize_width, resize_height, 3), name=\"encoder_input\")\n",
    "x = keras.layers.Conv2D(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(encoder_input)\n",
    "x = keras.layers.Conv2D(64, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
    "x = keras.layers.Conv2D(128, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
    "shape_before_flattening = K.int_shape(x)[1:]\n",
    "x = keras.layers.Flatten()(x)\n",
    "z_mean = keras.layers.Dense(200, name=\"z_mean\")(x)\n",
    "z_log_var = keras.layers.Dense(200, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.models.Model(encoder_input, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "\n",
    "#디코더 부분\n",
    "decoder_input = keras.layers.Input(shape=(200,), name=\"decoder_input\")\n",
    "x = keras.layers.Dense(np.prod(shape_before_flattening))(decoder_input)\n",
    "x = keras.layers.Reshape(shape_before_flattening)(x)\n",
    "x = keras.layers.Conv2DTranspose(128, (3, 3), strides=2, activation = 'relu', padding=\"same\")(x)\n",
    "x = keras.layers.Conv2DTranspose(64, (3, 3), strides=2, activation = 'relu', padding=\"same\")(x)\n",
    "x = keras.layers.Conv2DTranspose(32, (3, 3), strides=2, activation = 'relu', padding=\"same\")(x)\n",
    "decoder_output = keras.layers.Conv2D(3,(3, 3),strides = 1, activation=\"relu\", padding=\"same\", name=\"decoder_output\")(x)\n",
    "decoder = keras.models.Model(decoder_input, decoder_output, name=\"decoder\")\n",
    "\n",
    "encoder.summary()\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.models.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "        #loss 값을 모니터링 하는 요소\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name='total_loss')\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "    \n",
    "    def call(self, input):\n",
    "        z_mean, z_log_var, z = encoder(input)\n",
    "        reconstruction = decoder(z)\n",
    "        return z_mean, z_log_var, reconstruction\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, reconstruction = self(data)\n",
    "            reconstruction_loss = tf.reduce_mean(500 * tf.losses.binary_crossentropy(data, reconstruction, axis=(1,2,3)))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(-0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)), axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 새로 정의할때\n",
    "vae = VAE(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.compile(optimizer=\"adam\")\n",
    "vae.fit(images, epochs=200000, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 중에서 무작위로 하나 선택\n",
    "random_index1 = random.randint(0, len(images) - 1)\n",
    "selected_image1 = images[random_index1]\n",
    "\n",
    "# 또 다른 이미지를 무작위로 선택\n",
    "random_index2 = random.randint(0, len(images) - 1)\n",
    "selected_image2 = images[random_index2]\n",
    "\n",
    "# 선택한 이미지 표시\n",
    "plt.figure(figsize=(10, 5))  # 그림 크기 조정\n",
    "plt.subplot(1, 2, 1)  # 1x2 그리드의 첫 번째 위치\n",
    "plt.imshow(selected_image1)\n",
    "plt.title(\"Original Image 1\")\n",
    "\n",
    "# 인코더에 넣어서 임베딩 벡터 확인\n",
    "embedded1 = np.array(encoder.predict(np.array([selected_image1])))[2]\n",
    "\n",
    "# 임베딩 벡터를 디코더에 넣어서 결과값 예측\n",
    "predicted_img1 = decoder.predict(embedded1)\n",
    "plt.subplot(1, 2, 2)  # 1x2 그리드의 두 번째 위치\n",
    "plt.imshow(predicted_img1.reshape(resize_width, resize_height, 3))\n",
    "plt.title(\"Reconstructed Image 1\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 선택한 다른 이미지 표시\n",
    "plt.figure(figsize=(10, 5))  # 그림 크기 조정\n",
    "plt.subplot(1, 2, 1)  # 1x2 그리드의 첫 번째 위치\n",
    "plt.imshow(selected_image2)\n",
    "plt.title(\"Original Image 2\")\n",
    "\n",
    "# 인코더에 넣어서 임베딩 벡터 확인\n",
    "embedded2 = np.array(encoder.predict(np.array([selected_image2])))[2]\n",
    "\n",
    "# 임베딩 벡터를 디코더에 넣어서 결과값 예측\n",
    "predicted_img2 = decoder.predict(embedded2)\n",
    "plt.subplot(1, 2, 2)  # 1x2 그리드의 두 번째 위치\n",
    "plt.imshow(predicted_img2.reshape(resize_width, resize_height, 3))\n",
    "plt.title(\"Reconstructed Image 2\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 두 이미지의 임베딩 벡터의 중간값을 이용해 결과값 예측\n",
    "predicted_img_combined = decoder.predict((embedded1 + embedded2) / 2)\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(predicted_img_combined.reshape(resize_width, resize_height, 3))\n",
    "plt.title(\"Reconstructed Combined Image\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vae.save_weights('vae_weight_celebA.h5')\n",
    "# vae.load_weights('vae_weight_celebA.h5')\n",
    "\n",
    "vae.save_weights('vae_sweight_av.h5')\n",
    "# vae.load_weights('vae_sweight_av.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
