{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.constraints import Constraint\n",
    "from tensorflow.keras.datasets import cifar10  # CIFAR-10 데이터셋 예제로 사용\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# GPU 디바이스 목록 가져오기\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    print(\"사용 가능한 GPU 디바이스:\")\n",
    "    for gpu in gpus:\n",
    "        print(\"디바이스 이름:\", gpu.name)\n",
    "else:\n",
    "    print(\"사용 가능한 GPU 디바이스가 없습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 전처리 코드\n",
    "\n",
    "# image_dir = \"C:\\\\Users\\\\crazy\\\\Downloads\\\\archive\\\\img_align_celeba\\\\img_align_celeba\"\n",
    "# image_dir = \"C:\\\\Users\\\\crazy\\\\Downloads\\\\archive\\\\img_align_celeba\\\\10000\"\n",
    "# image_dir = \"C:\\\\Users\\\\crazy\\\\Downloads\\\\archive\\\\img_align_celeba\\\\10\"\n",
    "# image_dir = \"C:\\\\Myfolder\\\\AI_tools\\\\dfl\\\\df_NVIDIA_RTX3000_series\\\\workspace\\\\data_src\\\\aligned\"\n",
    "# image_dir = \"C:\\\\Myfolder\\\\AI_tools\\\\sd.webui\\\\this\\\\fun\\\\image\"\n",
    "# image_dir = \"C:\\\\Users\\\\crazy\\Downloads\\\\archive\\\\img_align_celeba\\\\facesetav\"\n",
    "image_dir = \"C:\\\\Users\\\\crazy\\Downloads\\\\archive\\\\img_align_celeba\\\\picted\"\n",
    "# crop_width, crop_height = 1024, 1024  # 자를 크기\n",
    "resize_width, resize_height = 128, 128  # 변경할 크기\n",
    "\n",
    "# 이미지 목록 가져오기\n",
    "image_files = os.listdir(image_dir)\n",
    "\n",
    "# 이미지를 NumPy 배열로 로드하고 크기 변경하기\n",
    "images = []\n",
    "for filename in image_files:\n",
    "    img = tf.keras.preprocessing.image.load_img(os.path.join(image_dir, filename), target_size=(resize_width, resize_height))\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img = img / 255.0  # 이미지 정규화\n",
    "    images.append(img)\n",
    "images = np.array(images)\n",
    "\n",
    "\n",
    "# 이미지 중에서 무작위로 하나 선택\n",
    "random_index = random.randint(0, len(images) - 1)\n",
    "selected_image = images[random_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    noise = Input(shape=(100,))\n",
    "    x = Dense(4 * 4 * 512)(noise)\n",
    "    x = Reshape((4, 4, 512))(x)\n",
    "    x = Conv2DTranspose(256, kernel_size=5, strides=2, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Conv2DTranspose(128, kernel_size=5, strides=2, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Conv2DTranspose(3, kernel_size=5, strides=8, padding='same', activation='tanh')(x)\n",
    "    generator = Model(noise, x)\n",
    "    return generator\n",
    "\n",
    "def build_discriminator():\n",
    "    img_input = Input(shape=(128, 128, 3))\n",
    "    x = Conv2D(64, kernel_size=5, strides=2, padding='same')(img_input)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Conv2D(128, kernel_size=5, strides=2, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Conv2D(256, kernel_size=5, strides=2, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Flatten()(x)\n",
    "    validity = Dense(100)(x)\n",
    "    discriminator = Model(img_input, validity)\n",
    "    return discriminator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientPenalty(Constraint):\n",
    "    def __init__(self, weight=10.0):\n",
    "        self.weight = weight\n",
    "\n",
    "    def __call__(self, w):\n",
    "        batch_size = tf.shape(w)[0]\n",
    "        epsilon = tf.random.uniform((batch_size, 1, 1, 1))\n",
    "        interpolated = epsilon * w + (1 - epsilon) * (w + 0.5 * tf.random.normal(tf.shape(w)))\n",
    "        gradient_penalty = self.weight * tf.reduce_sum(tf.square(interpolated - w))\n",
    "        return gradient_penalty\n",
    "\n",
    "mse_loss = MeanSquaredError()\n",
    "\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return -tf.reduce_mean(y_true * y_pred)\n",
    "\n",
    "def gradient_penalty_loss(y_true, y_pred, averaged_samples):\n",
    "    gradients = tf.gradients(y_pred, averaged_samples)[0]\n",
    "    gradients_sqr = tf.square(gradients)\n",
    "    gradients_sqr_sum = tf.reduce_sum(gradients_sqr, axis=np.arange(1, len(gradients_sqr.shape)))\n",
    "    gradient_l2_norm = tf.sqrt(gradients_sqr_sum)\n",
    "    gradient_penalty = tf.reduce_mean((gradient_l2_norm - 1) ** 2)\n",
    "    return gradient_penalty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_16 (InputLayer)       [(None, 100)]             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 8192)              827392    \n",
      "                                                                 \n",
      " reshape_3 (Reshape)         (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_9 (Conv2DT  (None, 8, 8, 256)        3277056   \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_15 (LeakyReLU)  (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_10 (Conv2D  (None, 16, 16, 128)      819328    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_16 (LeakyReLU)  (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_11 (Conv2D  (None, 128, 128, 3)      9603      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,934,915\n",
      "Trainable params: 4,934,147\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_17 (InputLayer)       [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 64, 64, 64)        4864      \n",
      "                                                                 \n",
      " leaky_re_lu_17 (LeakyReLU)  (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 32, 32, 128)       204928    \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 32, 32, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_18 (LeakyReLU)  (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 16, 16, 256)       819456    \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 16, 16, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_19 (LeakyReLU)  (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 65536)             0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 100)               6553700   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,584,484\n",
      "Trainable params: 7,583,716\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = build_generator()\n",
    "discriminator = build_discriminator()\n",
    "\n",
    "generator.summary()\n",
    "discriminator.summary()\n",
    "\n",
    "# 판별자의 가중치 제약을 추가합니다.\n",
    "for layer in discriminator.layers:\n",
    "    if isinstance(layer, Conv2D):\n",
    "        layer.kernel_constraint = GradientPenalty()\n",
    "\n",
    "real_img = Input(shape=(128, 128, 3))\n",
    "fake_img = generator(Input(shape=(100,)))\n",
    "\n",
    "validity_real = discriminator(real_img)\n",
    "validity_fake = discriminator(fake_img)\n",
    "\n",
    "discriminator_model = Model(inputs=[real_img, fake_img], outputs=[validity_real, validity_fake])\n",
    "\n",
    "# 판별자와 생성자 모델의 컴파일\n",
    "discriminator_model.compile(optimizer=RMSprop(0.00005), loss=[wasserstein_loss, wasserstein_loss],\n",
    "                            loss_weights=[1, 1])\n",
    "generator.compile(optimizer=RMSprop(0.00005), loss=wasserstein_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\crazy\\OneDrive\\Desktop\\Latent Diffusion\\.conda\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\crazy\\AppData\\Local\\Temp\\ipykernel_16708\\2536175825.py\", line 15, in wasserstein_loss  *\n        return -tf.reduce_mean(y_true * y_pred)\n\n    ValueError: Dimensions must be equal, but are 64 and 128 for '{{node wasserstein_loss/mul}} = Mul[T=DT_FLOAT](IteratorGetNext:1, model_9/conv2d_transpose_11/Tanh)' with input shapes: [64,1], [64,128,128,3].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\crazy\\OneDrive\\Desktop\\Latent Diffusion\\WGAN_GP-gptmade.ipynb 셀 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/crazy/OneDrive/Desktop/Latent%20Diffusion/WGAN_GP-gptmade.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m noise \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mnormal(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, (batch_size, \u001b[39m100\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/crazy/OneDrive/Desktop/Latent%20Diffusion/WGAN_GP-gptmade.ipynb#W4sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m valid \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39mones((batch_size, \u001b[39m1\u001b[39m))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/crazy/OneDrive/Desktop/Latent%20Diffusion/WGAN_GP-gptmade.ipynb#W4sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m g_loss \u001b[39m=\u001b[39m generator\u001b[39m.\u001b[39;49mtrain_on_batch(noise, valid)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/crazy/OneDrive/Desktop/Latent%20Diffusion/WGAN_GP-gptmade.ipynb#W4sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mif\u001b[39;00m epoch \u001b[39m%\u001b[39m sample_interval \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/crazy/OneDrive/Desktop/Latent%20Diffusion/WGAN_GP-gptmade.ipynb#W4sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m, D Loss Real: \u001b[39m\u001b[39m{\u001b[39;00md_loss_real[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m, G Loss: \u001b[39m\u001b[39m{\u001b[39;00mg_loss\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\crazy\\OneDrive\\Desktop\\Latent Diffusion\\.conda\\lib\\site-packages\\keras\\engine\\training.py:2381\u001b[0m, in \u001b[0;36mModel.train_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   2377\u001b[0m     iterator \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39msingle_batch_iterator(\n\u001b[0;32m   2378\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy, x, y, sample_weight, class_weight\n\u001b[0;32m   2379\u001b[0m     )\n\u001b[0;32m   2380\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_train_function()\n\u001b[1;32m-> 2381\u001b[0m     logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   2383\u001b[0m logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   2384\u001b[0m \u001b[39mif\u001b[39;00m return_dict:\n",
      "File \u001b[1;32mc:\\Users\\crazy\\OneDrive\\Desktop\\Latent Diffusion\\.conda\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filemfd9h5kk.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\crazy\\OneDrive\\Desktop\\Latent Diffusion\\.conda\\lib\\site-packages\\keras\\engine\\training.py:1146\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1142\u001b[0m     run_step \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mfunction(\n\u001b[0;32m   1143\u001b[0m         run_step, jit_compile\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, reduce_retracing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m     )\n\u001b[0;32m   1145\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(iterator)\n\u001b[1;32m-> 1146\u001b[0m outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mdistribute_strategy\u001b[39m.\u001b[39;49mrun(run_step, args\u001b[39m=\u001b[39;49m(data,))\n\u001b[0;32m   1147\u001b[0m outputs \u001b[39m=\u001b[39m reduce_per_replica(\n\u001b[0;32m   1148\u001b[0m     outputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy, reduction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfirst\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1149\u001b[0m )\n\u001b[0;32m   1150\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\crazy\\OneDrive\\Desktop\\Latent Diffusion\\.conda\\lib\\site-packages\\keras\\engine\\training.py:1135\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(data):\n\u001b[1;32m-> 1135\u001b[0m     outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain_step(data)\n\u001b[0;32m   1136\u001b[0m     \u001b[39m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[1;32mc:\\Users\\crazy\\OneDrive\\Desktop\\Latent Diffusion\\.conda\\lib\\site-packages\\keras\\engine\\training.py:994\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    992\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[0;32m    993\u001b[0m     y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m(x, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> 994\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(x, y, y_pred, sample_weight)\n\u001b[0;32m    995\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_target_and_loss(y, loss)\n\u001b[0;32m    996\u001b[0m \u001b[39m# Run backwards pass.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\crazy\\OneDrive\\Desktop\\Latent Diffusion\\.conda\\lib\\site-packages\\keras\\engine\\training.py:1052\u001b[0m, in \u001b[0;36mModel.compute_loss\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1001\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compute the total loss, validate it, and return it.\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m \n\u001b[0;32m   1003\u001b[0m \u001b[39mSubclasses can optionally override this method to provide custom loss\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[39m  is the case when called by `Model.test_step`).\u001b[39;00m\n\u001b[0;32m   1050\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m \u001b[39mdel\u001b[39;00m x  \u001b[39m# The default implementation does not use `x`.\u001b[39;00m\n\u001b[1;32m-> 1052\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompiled_loss(\n\u001b[0;32m   1053\u001b[0m     y, y_pred, sample_weight, regularization_losses\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlosses\n\u001b[0;32m   1054\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\crazy\\OneDrive\\Desktop\\Latent Diffusion\\.conda\\lib\\site-packages\\keras\\engine\\compile_utils.py:265\u001b[0m, in \u001b[0;36mLossesContainer.__call__\u001b[1;34m(self, y_true, y_pred, sample_weight, regularization_losses)\u001b[0m\n\u001b[0;32m    263\u001b[0m y_t, y_p, sw \u001b[39m=\u001b[39m match_dtype_and_rank(y_t, y_p, sw)\n\u001b[0;32m    264\u001b[0m sw \u001b[39m=\u001b[39m losses_utils\u001b[39m.\u001b[39mapply_mask(y_p, sw, losses_utils\u001b[39m.\u001b[39mget_mask(y_p))\n\u001b[1;32m--> 265\u001b[0m loss_value \u001b[39m=\u001b[39m loss_obj(y_t, y_p, sample_weight\u001b[39m=\u001b[39;49msw)\n\u001b[0;32m    267\u001b[0m total_loss_mean_value \u001b[39m=\u001b[39m loss_value\n\u001b[0;32m    268\u001b[0m \u001b[39m# Correct for the `Mean` loss metrics counting each replica as a\u001b[39;00m\n\u001b[0;32m    269\u001b[0m \u001b[39m# batch.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\crazy\\OneDrive\\Desktop\\Latent Diffusion\\.conda\\lib\\site-packages\\keras\\losses.py:152\u001b[0m, in \u001b[0;36mLoss.__call__\u001b[1;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    149\u001b[0m     call_fn \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[0;32m    150\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall, tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mcontrol_status_ctx()\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 152\u001b[0m losses \u001b[39m=\u001b[39m call_fn(y_true, y_pred)\n\u001b[0;32m    153\u001b[0m mask \u001b[39m=\u001b[39m losses_utils\u001b[39m.\u001b[39mget_mask(losses)\n\u001b[0;32m    154\u001b[0m reduction \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_reduction()\n",
      "File \u001b[1;32mc:\\Users\\crazy\\OneDrive\\Desktop\\Latent Diffusion\\.conda\\lib\\site-packages\\keras\\losses.py:272\u001b[0m, in \u001b[0;36mLossFunctionWrapper.call\u001b[1;34m(self, y_true, y_pred)\u001b[0m\n\u001b[0;32m    265\u001b[0m     y_pred, y_true \u001b[39m=\u001b[39m losses_utils\u001b[39m.\u001b[39msqueeze_or_expand_dimensions(\n\u001b[0;32m    266\u001b[0m         y_pred, y_true\n\u001b[0;32m    267\u001b[0m     )\n\u001b[0;32m    269\u001b[0m ag_fn \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[0;32m    270\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn, tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mcontrol_status_ctx()\n\u001b[0;32m    271\u001b[0m )\n\u001b[1;32m--> 272\u001b[0m \u001b[39mreturn\u001b[39;00m ag_fn(y_true, y_pred, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fn_kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file_v3uq7xf.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__wasserstein_loss\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m     retval_ \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mreduce_mean, (ag__\u001b[39m.\u001b[39mld(y_true) \u001b[39m*\u001b[39m ag__\u001b[39m.\u001b[39mld(y_pred),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     13\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\crazy\\OneDrive\\Desktop\\Latent Diffusion\\.conda\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\crazy\\AppData\\Local\\Temp\\ipykernel_16708\\2536175825.py\", line 15, in wasserstein_loss  *\n        return -tf.reduce_mean(y_true * y_pred)\n\n    ValueError: Dimensions must be equal, but are 64 and 128 for '{{node wasserstein_loss/mul}} = Mul[T=DT_FLOAT](IteratorGetNext:1, model_9/conv2d_transpose_11/Tanh)' with input shapes: [64,1], [64,128,128,3].\n"
     ]
    }
   ],
   "source": [
    "# 훈련 설정\n",
    "epochs = 20000\n",
    "batch_size = 64\n",
    "sample_interval = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    idx = np.random.randint(0, images.shape[0], batch_size)\n",
    "    real_imgs = images[idx]\n",
    "\n",
    "    noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "    fake_imgs = generator.predict(noise)\n",
    "\n",
    "    d_loss_real = discriminator_model.train_on_batch([real_imgs, fake_imgs], [-np.ones((batch_size, 1)), np.ones((batch_size, 1))])\n",
    "    \n",
    "    noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "    valid = -np.ones((batch_size, 1))\n",
    "    g_loss = generator.train_on_batch(noise, valid)\n",
    "\n",
    "    if epoch % sample_interval == 0:\n",
    "        print(f\"Epoch {epoch}, D Loss Real: {d_loss_real[0]}, G Loss: {g_loss}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
