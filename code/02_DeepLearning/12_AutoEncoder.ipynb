{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoEncoder\n",
    "\n",
    "입력 데이터를 효율적으로 **압축, 복원** 하여 학습에 용이하게 하거나 노이즈를 제거.\n",
    "\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:720/format:webp/1*44eDEuZBEsmG_TCAKRI3Kw@2x.png\" height=\"400\">\n",
    "\n",
    "- AE의 구조\n",
    "    - Encoder\n",
    "        1. 입력 데이터를 저차원의 벡터로 매핑\n",
    "        2. 특성의 추출 구간\n",
    "    - Latent Space(잠재 공간) : 입력 데이터를 축약하고 있는 특성 벡터\n",
    "    - Decoder\n",
    "        1. 인코더와 대칭\n",
    "        2. 복원하는 구간\n",
    "\n",
    "- AE의 특징 : \n",
    "    - 기본적으로 RNN과 같이 Dense층으로 구성 되어져 있다.\n",
    "    - 하지만 구조상 일반적으로(아닐 수도 있음) 대칭이고, 잠재 공간(z or **code**) 이라는 층이 존재 한다.\n",
    "    - 잠재 공간 벡터를 복구하는 구간이 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder\n",
    "- 차원 축소\n",
    "- 일종의 Trade Off 가 있다. (잠재공간의 차원을 높일 것인가, 특성을 얼마나 압축할 것인가.)\n",
    "\n",
    "### Latent Space(Code or z)\n",
    "- 입력데이터의 중요한 특성을 반영하고 있다.\n",
    "- 입력 데이터에 대한 압축 표현(**벡터**) : 차원의 저주를 완화시킨다.\n",
    "\n",
    "### Decoder\n",
    "- 생성형 모델(잠재공간을 다시 복구하는 과정에서 이미지가 생성)\n",
    "\n",
    "### Loss\n",
    "$$\\mathscr{L} = \\frac{1}{n} \\sum({x_i - \\hat{x_i})^2}$$\n",
    "\n",
    "- 재 구성과정의 오차의 최소화\n",
    "- MSE 또는 CEE 등이 쓰인다.\n",
    "- 여기서 $x_i$  는 입력 값이지만 예측에 대한 정답 라벨이기도 하다.\n",
    "\n",
    "### AE 응용\n",
    "\n",
    "1. $z = f(x)$ : 인코더 부분\n",
    "2. $\\hat x = g(z)$ : 디코더 부분\n",
    "3. $\\mathscr{L} = \\frac{1}{n} \\sum({x_i - \\hat{x_i})^2}$ : MSE or CEE\n",
    "\n",
    "- 응용\n",
    "    - 입력 데이터의 압축 및 복원 → 효율적인 데이터 저장 및 전송\n",
    "    - **차원의 축소** (PCA 와 비슷하나, 좀더 비선형적이다)\n",
    "\n",
    "\n",
    "        | 특징 | PCA | AE |\n",
    "        | --- | --- | --- |\n",
    "        | 변환 | 선형 | 비선형 |\n",
    "        | 구현 | 공분산, 행렬의 고유벡터 | NN기반 Encoder, Decoder |\n",
    "        | 계산 복잡 | 낮음 | 복잡 |\n",
    "        | 해석 | 용이 | 어려움 |\n",
    "        | 유연성  | 낮다  | 높다 |\n",
    "        <br>\n",
    "    - **노이즈 제거** → 중요 특성을 추출 하여 노이즈를 제거한다.\n",
    "        1. 입력 값에 노이즈를 추가해 AE의 입력 값으로 넣는다\n",
    "        2. 출력 과 비교할 정답 라벨로 노이즈가 추가되기 전의 입력 데이터로 넣는다\n",
    "\n",
    "        $x_i$ : 원래의 입력\n",
    "\n",
    "        $x'_i$ : 노이즈 된 입력\n",
    "\n",
    "        순 전파 시 입력 데이터를 $x'_i$ 이용,\n",
    "\n",
    "        정답 라벨과 Loss 값을 구할 때 $x_i$ 이용.\n",
    "\n",
    "        - 새로운 데이터가 들어올 때 노이즈가 제거 된다.\n",
    "    - **추천 시스템** (수천가지의 특성 들을 잠재공간에 넘기는 과정)\n",
    "    - **이상치 탐지**\n",
    "        1. 일반 적인 방법으로 AE학습\n",
    "        2. 새로운 데이터를 넣어 재구성손실을 이용하여 이상치를 탐지한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mnist data를 이용한 AE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 인코더 디코더 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Embedding, Flatten ### Input 모델의 입력을 정의할 때 \n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.regularizers import l1 ### 정규화 과적합 방지\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 인풋 스케일링\n",
    "x_train1 = x_train.astype('float32')/255\n",
    "x_test1 = x_test.astype('float32')/255\n",
    "\n",
    "x_train = x_train1.reshape((60000, 28*28))\n",
    "x_test = x_test1.reshape((10000, 28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1729413312.562628   22469 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729413312.611162   22469 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729413312.616174   22469 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729413312.623034   22469 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729413312.628389   22469 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729413312.631746   22469 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729413312.759092   22469 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729413312.760805   22469 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1729413312.762437   22469 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-10-20 17:35:12.764114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9593 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "input_size = 784\n",
    "hidden_size = 128\n",
    "# z 의 크기\n",
    "code_size = 32\n",
    "\n",
    "input_img = Input(shape=(input_size,))\n",
    "hidden_1 = Dense(hidden_size, activation='relu')(input_img)\n",
    "code = Dense(code_size, activation='relu')(hidden_1) # 잠재 공간\n",
    "\n",
    "hidden_2 = Dense(hidden_size, activation='relu')(code)\n",
    "output_img = Dense(input_size, activation='sigmoid')(hidden_2)\n",
    "\n",
    "autoencoder = Model(input_img, output_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1729413314.557410   27121 service.cc:146] XLA service 0x72a1f0004ca0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1729413314.557430   27121 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2024-10-20 17:35:14.587010: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-10-20 17:35:14.703746: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 208/1875\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 764us/step - loss: 0.0999"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1729413317.574623   27121 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 689us/step - loss: 0.0433\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 651us/step - loss: 0.0130\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662us/step - loss: 0.0110\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647us/step - loss: 0.0100\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668us/step - loss: 0.0094\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0094 \n",
      "Test loss: 0.009063614532351494\n"
     ]
    }
   ],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "autoencoder.fit(x_train, x_train, epochs=5)\n",
    "test_loss = autoencoder.evaluate(x_test, x_test)\n",
    "print(\"Test loss:\", test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 인코더 모델(잠재공간 벡터만 이용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 576us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tommy/miniconda3/envs/311/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "encoder = Model(inputs=input_img, outputs=code)\n",
    "\n",
    "### encode 훈련셋\n",
    "X_train_encode = encoder.predict(x_train)  ### 32차원의 저차원 벡터 생성\n",
    "### encode 검증셋\n",
    "X_test_encode = encoder.predict(x_test)\n",
    "\n",
    "### 단순히 시퀀셜한 구성으로 사용\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(128, activation = 'relu', input_shape=(X_train_encode.shape[1],)))\n",
    "model.add(layers.Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6343 - loss: 1.3541 - val_accuracy: 0.8958 - val_loss: 0.3717\n",
      "Epoch 2/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 731us/step - accuracy: 0.8802 - loss: 0.3876 - val_accuracy: 0.9165 - val_loss: 0.2874\n",
      "Epoch 3/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - accuracy: 0.9020 - loss: 0.3163 - val_accuracy: 0.9259 - val_loss: 0.2506\n",
      "Epoch 4/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.9210 - loss: 0.2612 - val_accuracy: 0.9359 - val_loss: 0.2158\n",
      "Epoch 5/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - accuracy: 0.9330 - loss: 0.2224 - val_accuracy: 0.9237 - val_loss: 0.2345\n",
      "Epoch 6/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - accuracy: 0.9407 - loss: 0.1972 - val_accuracy: 0.9458 - val_loss: 0.1785\n",
      "Epoch 7/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 713us/step - accuracy: 0.9470 - loss: 0.1717 - val_accuracy: 0.9404 - val_loss: 0.1862\n",
      "Epoch 8/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - accuracy: 0.9495 - loss: 0.1695 - val_accuracy: 0.9553 - val_loss: 0.1486\n",
      "Epoch 9/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - accuracy: 0.9543 - loss: 0.1474 - val_accuracy: 0.9572 - val_loss: 0.1433\n",
      "Epoch 10/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 0.9557 - loss: 0.1436 - val_accuracy: 0.9549 - val_loss: 0.1495\n",
      "Epoch 11/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - accuracy: 0.9584 - loss: 0.1332 - val_accuracy: 0.9611 - val_loss: 0.1298\n",
      "Epoch 12/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - accuracy: 0.9617 - loss: 0.1246 - val_accuracy: 0.9605 - val_loss: 0.1344\n",
      "Epoch 13/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 0.9616 - loss: 0.1250 - val_accuracy: 0.9588 - val_loss: 0.1324\n",
      "Epoch 14/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - accuracy: 0.9645 - loss: 0.1171 - val_accuracy: 0.9615 - val_loss: 0.1248\n",
      "Epoch 15/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - accuracy: 0.9653 - loss: 0.1102 - val_accuracy: 0.9638 - val_loss: 0.1208\n",
      "Epoch 16/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.9665 - loss: 0.1096 - val_accuracy: 0.9645 - val_loss: 0.1224\n",
      "Epoch 17/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - accuracy: 0.9687 - loss: 0.1018 - val_accuracy: 0.9612 - val_loss: 0.1332\n",
      "Epoch 18/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - accuracy: 0.9683 - loss: 0.0984 - val_accuracy: 0.9552 - val_loss: 0.1475\n",
      "Epoch 19/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - accuracy: 0.9689 - loss: 0.0986 - val_accuracy: 0.9624 - val_loss: 0.1252\n",
      "Epoch 20/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 712us/step - accuracy: 0.9701 - loss: 0.0973 - val_accuracy: 0.9662 - val_loss: 0.1154\n"
     ]
    }
   ],
   "source": [
    "rmsprop = optimizers.RMSprop(learning_rate=0.001)\n",
    "model.compile(optimizer=rmsprop,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train_encode, y_train_one_hot,\n",
    "\t\t\t\t\t\t\t\t\t\tepochs=20, batch_size=128, validation_split = 0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
