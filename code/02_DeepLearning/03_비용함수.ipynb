{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 비용함수\n",
    "\n",
    "- 예측과 정답과의 차이를 본다.\n",
    "- 가중치를 조정하기 위해\n",
    "- 네트워크가 최적을 예측 수행 하도록 학습\n",
    "\n",
    "- 역할 :\n",
    "  모델 평가 : 예측과 실제의 차이를 수치적 표현하기 위해\n",
    "  모델 최적화 : 비용함수의 값을 최소화, 가중치 편향 조정 - 학습 과정\n",
    "\n",
    "### 회귀 문제\n",
    "\n",
    "- 평균 제곱 오차\n",
    "    \n",
    "    $\\text{MSE} = \\frac{1}{N} \\sum_{i=1}^{N} (y - \\hat{y})$\n",
    "    \n",
    "    - 나중에 루트를 씌어 실제와 비교 (제곱이므로)\n",
    "    - 큰 오차에 더 큰 가중치 (제곱이므로)\n",
    "    - 일반적인 사용\n",
    "- 평균 절대 오차\n",
    "    \n",
    "    $\\text{MAE} = \\frac{1}{N} \\sum_{i=1}^{N} |y - \\hat{y}|$\n",
    "    \n",
    "    - 이상치에 덜 민감\n",
    "    - 값 자체로의 해석이 가능하다.\n",
    "- 허브 손실\n",
    "    \n",
    "    $L_\\delta(y,\\hat{y}) = \\begin{cases} \\frac{1}{2} (y - \\hat{y})^2 & \\text{if} \\quad|y - \\hat{y}| \\leq \\delta \\\\ \\delta |y - \\hat{y}| - \\frac{1}{2} \\delta^2 & \\text{if} \\quad|y-\\hat{y}| > \\delta \\end{cases}$\n",
    "    \n",
    "    - MAE 와 MSE 와의 조합\n",
    "    - 오차가 클 때 : MSE, 오차가 작을 때 : MAE\n",
    "    - 여기서 $\\delta$ 는 임계값\n",
    "- 로그 코사인 유도\n",
    "    \n",
    "    $\\log - \\cosh = \\frac{1}{N} \\sum^{N}_{i = 1} \\log({\\cosh (\\hat{y}-y)})$\n",
    "    \n",
    "    - 오차의 cosh 의 log\n",
    "    - 이상치에 매우 강하다, 최적화에 장점을 가지고 있다.\n",
    "\n",
    "### 분류 문제\n",
    "\n",
    "- 교차 엔트로피 손실\n",
    "    - 이진 분류에서 사용(다중 분류시 Categorical 교체 엔트로피 이용)\n",
    "    - 예측과의 차이를 보여줌\n",
    "    - 실제와 가까울 수록, 손실은 적어짐\n",
    "- 힌지 손실\n",
    "    - 주로 SVM 에서 사용\n",
    "    - 이진분류의 마진오류의 최소화\n",
    "- 제곱 힌지 손실\n",
    "    - 힌지 손실의 제곱\n",
    "    - 이상치에 민감\n",
    "- 로지스틱 손실\n",
    "    - 이진분류에 적합, 로지스틱 회귀에서 자주 사용\n",
    "    - 예측과 실제 사이의 로그 손실\n",
    "- 포칼 손실\n",
    "    - 클래스 불균형이 심한 문제\n",
    "    - 정답 보다, 오답 분류에 대한 가중치 부여\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 비용함수 예제 : 회귀 문제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse : 0.010000000000000018\n",
      "mae : 0.10000000000000009\n",
      "huber : 0.005000000000000009\n",
      "log_cosh : 0.004991688821646436\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 예측값과 실제값\n",
    "y_true = np.array([1.0, 2.0, 3.0])\n",
    "y_pred = np.array([1.1, 1.9, 3.1])\n",
    "\n",
    "# 평균 제곱 오차 (Mean Squared Error)\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "# 평균 절대 오차 (Mean Absolute Error)\n",
    "def mean_absolute_error(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "# 허브(Huber) 손실\n",
    "def huber_loss(y_true, y_pred, delta=1.0):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = np.abs(error) <= delta\n",
    "    squared_loss = 0.5 * error**2\n",
    "    linear_loss = delta * (np.abs(error) - 0.5 * delta)\n",
    "    return np.mean(np.where(is_small_error, squared_loss, linear_loss))\n",
    "\n",
    "# 로그 코사인 유사도 (Log-Cosh Loss)\n",
    "def log_cosh_loss(y_true, y_pred):\n",
    "    return np.mean(np.log(np.cosh(y_pred - y_true)))\n",
    "\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "huber = huber_loss(y_true, y_pred, delta=1.0)\n",
    "log_cosh = log_cosh_loss(y_true, y_pred)\n",
    "\n",
    "print(f\"\"\"\\\n",
    "mse : {mse}\n",
    "mae : {mae}\n",
    "huber : {huber}\n",
    "log_cosh : {log_cosh}\\\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 비용함수 예제 : 분류 문제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss, hinge_loss\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예시 데이터: 실제 레이블과 예측 확률\n",
    "y_true = np.array([1, 0, 1, 1, 0])\n",
    "y_pred_probs = np.array([0.9, 0.1, 0.8, 0.65, 0.3]) # 이진 분류의 예측 확률\n",
    "y_pred = np.array([1, 0, 1, 1, 0]) # 정답\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24426448853220978"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 교차 엔트로피 손실\n",
    "cross_entropy_loss = log_loss(y_true, y_pred_probs)\n",
    "cross_entropy_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 힌지 손실\n",
    "hinge_loss_value = hinge_loss(y_true, 2*y_pred-1)  # hinge_loss는 -1과 1의 레이블을 기대합니다.\n",
    "hinge_loss_value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
