{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "WaE2nzTV7o9D"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.40.6-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/tommy/miniconda3/envs/py311/lib/python3.11/site-packages (from openai) (4.4.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/tommy/miniconda3/envs/py311/lib/python3.11/site-packages (from openai) (0.27.0)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sniffio in /home/tommy/miniconda3/envs/py311/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/tommy/miniconda3/envs/py311/lib/python3.11/site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/tommy/miniconda3/envs/py311/lib/python3.11/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/tommy/miniconda3/envs/py311/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in /home/tommy/miniconda3/envs/py311/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /home/tommy/miniconda3/envs/py311/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/tommy/miniconda3/envs/py311/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.20.1 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Downloading openai-1.40.6-py3-none-any.whl (361 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m361.3/361.3 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.2/319.2 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.9/423.9 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: pydantic-core, jiter, distro, annotated-types, pydantic, openai\n",
      "Successfully installed annotated-types-0.7.0 distro-1.9.0 jiter-0.5.0 openai-1.40.6 pydantic-2.8.2 pydantic-core-2.20.1\n"
     ]
    }
   ],
   "source": [
    "!pip install openai  # Install the OpenAI library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MBfeeo7T9b84"
   },
   "outputs": [],
   "source": [
    "# pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "aFn3TNBK-sIG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai==0.28\n",
      "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: requests>=2.20 in /home/tommy/miniconda3/envs/py311/lib/python3.11/site-packages (from openai==0.28) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /home/tommy/miniconda3/envs/py311/lib/python3.11/site-packages (from openai==0.28) (4.66.5)\n",
      "Requirement already satisfied: aiohttp in /home/tommy/miniconda3/envs/py311/lib/python3.11/site-packages (from openai==0.28) (3.10.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/tommy/miniconda3/envs/py311/lib/python3.11/site-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/tommy/miniconda3/envs/py311/lib/python3.11/site-packages (from requests>=2.20->openai==0.28) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/tommy/miniconda3/envs/py311/lib/python3.11/site-packages (from requests>=2.20->openai==0.28) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/tommy/miniconda3/envs/py311/lib/python3.11/site-packages (from requests>=2.20->openai==0.28) (2024.7.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/tommy/miniconda3/envs/py311/lib/python3.11/site-packages (from aiohttp->openai==0.28) (2.3.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/tommy/miniconda3/envs/py311/lib/python3.11/site-packages (from aiohttp->openai==0.28) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/tommy/miniconda3/envs/py311/lib/python3.11/site-packages (from aiohttp->openai==0.28) (24.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/tommy/miniconda3/envs/py311/lib/python3.11/site-packages (from aiohttp->openai==0.28) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/tommy/miniconda3/envs/py311/lib/python3.11/site-packages (from aiohttp->openai==0.28) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/tommy/miniconda3/envs/py311/lib/python3.11/site-packages (from aiohttp->openai==0.28) (1.9.4)\n",
      "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 0.27.0\n",
      "    Uninstalling openai-0.27.0:\n",
      "      Successfully uninstalled openai-0.27.0\n",
      "Successfully installed openai-0.28.0\n"
     ]
    }
   ],
   "source": [
    "!pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ql8J1Ux97-zc"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_key='secret'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SUG_lyIM8BpN"
   },
   "outputs": [],
   "source": [
    "# OpenAI API 키 설정\n",
    "openai.api_key = gpt_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "caVC6dqCAzTQ",
    "outputId": "76056a93-67bf-4c27-a361-d5a80bb673a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! Here's a joke for you: Why don't scientists trust atoms? Because they make up everything! I hope it made you smile!\n"
     ]
    }
   ],
   "source": [
    "# 1: 기본적인 대화 생성\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",  # 사용 모델\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a friendly helper.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you tell me a joke?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 결과 출력\n",
    "print(response.choices[0].message['content'].strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hzV9ywWOA8xk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! The theory of relativity, developed by Albert Einstein, is actually two separate theories: special relativity and general relativity.\n",
      "\n",
      "Special relativity deals with the way things move at very high speeds. It states that the laws of physics are the same for all observers, regardless of their motion. It also introduces the idea that time and space are intertwined in a four-dimensional \"fabric\" called spacetime.\n",
      "\n",
      "General relativity, on the other hand, describes the force of gravity as the curvature of spacetime caused by mass and energy. In this theory, massive objects like planets and stars cause spacetime to warp, which in turn affects how objects move in space.\n",
      "\n",
      "In simple terms, the theory of relativity tells us that the way we perceive time and space depends on our motion and the presence of mass and energy. It also explains how gravity works in a different way than what was previously thought.\n"
     ]
    }
   ],
   "source": [
    "# 2:  설명 요청 - 교육\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",  # 사용 모델\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a knowledgeable teacher.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you explain the theory of relativity in simple terms?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 결과 출력\n",
    "print(response.choices[0].message['content'].strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "DA89AyYrBDb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improving time management skills involves being organized, setting priorities, and staying focused. Here are some tips to help you enhance your time management skills:\n",
      "\n",
      "1. Create a daily schedule or to-do list: Plan your day by listing tasks and activities with specific time slots. This will help you stay organized and focused on what needs to get done.\n",
      "\n",
      "2. Prioritize tasks: Identify the most important tasks that need to be completed and focus on them first. Use techniques like the Eisenhower Matrix to prioritize tasks based on importance and urgency.\n",
      "\n",
      "3. Set deadlines: Establish realistic deadlines for tasks to help you stay on track and avoid procrastination.\n",
      "\n",
      "4. Minimize distractions: Identify common distractions such as social media, emails, or interruptions, and find ways to limit them during designated work times.\n",
      "\n",
      "5. Break tasks into smaller steps: Large tasks can be overwhelming, so break them down into smaller, manageable steps to make them less daunting and easier to tackle.\n",
      "\n",
      "6. Delegate tasks: If possible, delegate tasks to others to lighten your workload and free up time for more important responsibilities.\n",
      "\n",
      "7. Learn to say no: Don't overcommit yourself and learn to decline requests or tasks that don't align with your priorities or goals.\n",
      "\n",
      "8. Take breaks: Allow yourself short breaks throughout the day to recharge and maintain focus and productivity.\n",
      "\n",
      "9. Reflect and adjust: Regularly evaluate your time management strategies to identify what's working well and what needs improvement. Adjust your approach accordingly.\n",
      "\n",
      "By implementing these tips and staying consistent in your efforts, you can enhance your time management skills and become more efficient and productive in managing your time.\n"
     ]
    }
   ],
   "source": [
    "# 3: 문제 해결 방법 제안\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",  # 사용 모델\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"How can I improve my time management skills?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 결과 출력\n",
    "print(response.choices[0].message['content'].strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rw8d097RBPHx",
    "outputId": "6b13e987-5851-488e-a8c1-381ce49b03c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this futuristic cityscape at night, towering skyscrapers reach up to the dark sky, their sleek and shiny exteriors illuminated by vibrant neon lights. Each building seems to be competing with the others in a dazzling display of colors, creating a mesmerizing skyline that dazzles the eye.\n",
      "\n",
      "Flying cars zip through the air between the skyscrapers, their futuristic designs and glowing engines leaving streaks of light behind them. The hum of their engines blends with the distant sounds of the bustling city below, creating a symphony of technology and progress.\n",
      "\n",
      "Digital billboards flash advertisements and holographic displays hover in the air, showcasing the latest products and technologies. The streets below are alive with activity, with people moving purposefully from one place to another, their faces illuminated by the neon glow that permeates the city.\n",
      "\n",
      "As night falls, the city comes alive in a whirlwind of light and sound, a testament to human innovation and imagination. In this futuristic metropolis, the possibilities seem endless, and the future feels bright and full of promise.\n"
     ]
    }
   ],
   "source": [
    "# 4: 이미지 생성\n",
    "\n",
    "# 이미지 설명 \n",
    "image_description_prompt = \"\"\"\n",
    "Describe a futuristic cityscape at night, with tall skyscrapers, neon lights, and flying cars.\n",
    "\"\"\"\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a creative visual artist.\"},\n",
    "        {\"role\": \"user\", \"content\": image_description_prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 결과 출력\n",
    "print(response.choices[0].message['content'].strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MfOInG74BZnM"
   },
   "outputs": [],
   "source": [
    "# 5: 이미지 분석\n",
    "\n",
    "# 이미지 분석을 위한 텍스트\n",
    "image_analysis_prompt = \"\"\"\n",
    "Analyze the given image and provide a detailed description. The image shows a bustling city center with people walking on the streets, cars driving by, and tall buildings in the background.\n",
    "\"\"\"\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert in image analysis.\"},\n",
    "        {\"role\": \"user\", \"content\": image_analysis_prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 결과 출력\n",
    "print(response.choices[0].message['content'].strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C9YPbb4qBZ83",
    "outputId": "0b279d99-6254-43f2-f2fd-873817ed4de1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능의 미래는 흥미롭고 도전적이다.\n"
     ]
    }
   ],
   "source": [
    "# 6: 번역\n",
    "\n",
    "# 영어 -> 한국어로 번역\n",
    "translation_prompt = \"Translate the following sentence into Korean: 'The future of artificial intelligence is both exciting and challenging.'\"\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a professional translator.\"},\n",
    "        {\"role\": \"user\", \"content\": translation_prompt}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 결과 출력\n",
    "print(response.choices[0].message['content'].strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "XobebqAf2U1C"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence involves machines, particularly computer systems, simulating human intelligence processes like learning, reasoning, and self-correction. AI applications include expert systems, speech recognition, and machine vision.\n"
     ]
    }
   ],
   "source": [
    "# 7: 텍스트 요약\n",
    "\n",
    "# 긴 텍스트를 요약하기 위한 입력\n",
    "long_text = \"\"\"\n",
    "Artificial intelligence is the simulation of human intelligence processes by machines, especially computer systems.\n",
    "These processes include learning (the acquisition of information and rules for using the information), reasoning (using rules to reach approximate or definite conclusions), and self-correction.\n",
    "Applications of AI include expert systems, speech recognition, and machine vision.\n",
    "\"\"\"\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert in summarization.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Summarize the following text: '{long_text}'\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 결과 출력\n",
    "print(response.choices[0].message['content'].strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qxpnm5fp_NVH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gTTS\n",
      "  Downloading gTTS-2.5.3-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /home/tommy/miniconda3/envs/py311/lib/python3.11/site-packages (from gTTS) (2.32.3)\n",
      "Collecting click<8.2,>=7.1 (from gTTS)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/tommy/miniconda3/envs/py311/lib/python3.11/site-packages (from requests<3,>=2.27->gTTS) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/tommy/miniconda3/envs/py311/lib/python3.11/site-packages (from requests<3,>=2.27->gTTS) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/tommy/miniconda3/envs/py311/lib/python3.11/site-packages (from requests<3,>=2.27->gTTS) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/tommy/miniconda3/envs/py311/lib/python3.11/site-packages (from requests<3,>=2.27->gTTS) (2024.7.4)\n",
      "Downloading gTTS-2.5.3-py3-none-any.whl (29 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: click, gTTS\n",
      "Successfully installed click-8.1.7 gTTS-2.5.3\n"
     ]
    }
   ],
   "source": [
    "# 음성 변환\n",
    "!pip install gTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "RwbmwUDSATnW"
   },
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "import os\n",
    "\n",
    "# 변환할 텍스트 입력\n",
    "text = \"안녕하세요 와우 어메이징\"\n",
    "\n",
    "# gTTS를 사용하여 텍스트를 음성으로 변환\n",
    "tts = gTTS(text=text, lang='ko')\n",
    "\n",
    "# 변환된 음성을 파일로 저장\n",
    "speech_file_path = \"speech_output.mp3\"\n",
    "tts.save(speech_file_path)\n",
    "\n",
    "# 저장된 음성 파일 재생 (로컬 환경에서만 동작)\n",
    "# os.system(f\"mpg321 {speech_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kgzJMsCrATY4",
    "outputId": "ab2ff7ce-555d-4734-9f13-a5886904b736"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요. 와우 어메이징!\n"
     ]
    }
   ],
   "source": [
    "# 8.음성변환, TTS\n",
    "\n",
    "# 음성 파일 경로 설정\n",
    "audio_file_path = \"speech_output.mp3\"\n",
    "\n",
    "# 음성을 텍스트로 변환\n",
    "audio_file = open(audio_file_path, \"rb\")\n",
    "response = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
    "\n",
    "# 결과 출력\n",
    "print(response['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ur3zVimVGHR5",
    "outputId": "816564d5-6935-4c09-ffae-99fa24cccf45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Image URL: https://oaidalleapiprodscus.blob.core.windows.net/private/org-CLPrdPtadAxzTZ2xjjbMpVMi/user-fLgG5QYw4c97AiGukZHIQE11/img-ISwNEId89jjYHaLUWGwIeyA2.png?st=2024-08-13T23%3A42%3A45Z&se=2024-08-14T01%3A42%3A45Z&sp=r&sv=2023-11-03&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-08-13T22%3A05%3A36Z&ske=2024-08-14T22%3A05%3A36Z&sks=b&skv=2023-11-03&sig=4hcqmXHcl7dHyFwufX36gpFXLMMx9qk%2BGnom68/XgY0%3D\n"
     ]
    }
   ],
   "source": [
    "# 9. 이미지 생성\n",
    "\n",
    "# 이미지 생성 \n",
    "response = openai.Image.create(\n",
    "    prompt=\"A futuristic cityscape at sunset\",\n",
    "    n=1,  # 생성할 이미지 수\n",
    "    size=\"1024x1024\"  # 이미지 크기\n",
    ")\n",
    "\n",
    "# 결과 출력 (생성된 이미지 URL)\n",
    "image_url = response['data'][0]['url']\n",
    "print(f\"Generated Image URL: {image_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UiA_5IxgGRZg",
    "outputId": "7c1eb22b-aad6-4f67-8f06-43d2fdebd632"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Image URL: https://oaidalleapiprodscus.blob.core.windows.net/private/org-CLPrdPtadAxzTZ2xjjbMpVMi/user-fLgG5QYw4c97AiGukZHIQE11/img-eiBUhHRtZYlhLfbeAEFl35uS.png?st=2024-08-14T00%3A14%3A06Z&se=2024-08-14T02%3A14%3A06Z&sp=r&sv=2023-11-03&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-08-13T22%3A21%3A00Z&ske=2024-08-14T22%3A21%3A00Z&sks=b&skv=2023-11-03&sig=ZP8RP/uTXKOpBZN0rM2SzKLHWPC5kNCFgz/XFVmpebQ%3D\n"
     ]
    }
   ],
   "source": [
    "# 이미지 생성\n",
    "response = openai.Image.create(\n",
    "    prompt=\"jojo's bizarre adventure, dragon ball, realistic, 3d\",\n",
    "    n=1,  # 생성할 이미지 수\n",
    "    size=\"1024x1024\"  # 이미지 크기\n",
    ")\n",
    "\n",
    "# 결과 출력 (생성된 이미지 URL)\n",
    "image_url = response['data'][0]['url']\n",
    "print(f\"Generated Image URL: {image_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나:시작\n",
      "\"시작\"의 끝 글자인 \"각\"으로 시작할게요. \"각도\"\n",
      "나:도롱\n",
      "\"도롱\"의 끝 글자인 \"롱\"으로 시작할게요. \"롱다리\"\n",
      "나:리불끽\n",
      "\"리불끽\"의 끝 글자인 \"끽\"으로 시작할게요. \"끽소\"\n",
      "나:끽소?\n",
      "\"끽소\"는 잘못된 단어입니다. 제가 졌습니다.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# 대화를 위한 메시지 리스트 초기화\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"끝말 잇기 로봇(단어만 가능, 너가 졌으면 졌습니다\\\n",
    "                                 라고 출력 사용자가 졌으면 사용자가 졌습니다 라고 출력\\\n",
    "                                사용자의 끝 글자와, 너의 첫글자가 틀리면 너가 진거야)\"},\n",
    "    {\"role\": \"user\", \"content\": \"지금 부터 끝말잇기를 시작한다.\"}\n",
    "]\n",
    "\n",
    "# 사용자 메시지 추가 함수\n",
    "def add_user_message(content):\n",
    "    messages.append({\"role\": \"user\", \"content\": content})\n",
    "1\n",
    "# API 호출 및 결과 출력 함수\n",
    "def get_response():\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages\n",
    "    )\n",
    "    # AI의 응답 추가\n",
    "    messages.append({\"role\": \"assistant\", \"content\": response.choices[0].message['content'].strip()})\n",
    "    return (response.choices[0].message['content'].strip())\n",
    "\n",
    "# 대화 예시\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    print(f'나:{user_input}')\n",
    "    add_user_message(user_input)\n",
    "    answer = get_response()\n",
    "    print(answer)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    if ('졌' in user_input) or ('졌' in answer):\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
