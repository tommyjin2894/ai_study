### ê¸°ë³¸ ì‹œê°í™” ì½”ë“œ
<details>
<summary>ğŸ§‘â€ğŸ’»codeğŸ§‘â€ğŸ’»</summary>

```py
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib as mpl
import matplotlib.pyplot as plt
import matplotlib_inline.backend_inline

matplotlib_inline.backend_inline.set_matplotlib_formats("png2x") # svg, retina, png2x ...
mpl.style.use("seaborn-v0_8")
mpl.rcParams.update({"figure.constrained_layout.use": True})
sns.set_context("paper") 
sns.set_palette("Set2") 
sns.set_style("whitegrid") 

# ì‹œìŠ¤í…œ í°íŠ¸íŒ¨ë°€ë¦¬ì— ë”°ë¼ ë³€ê²½
plt.rc("font", family = "NanumSquareRound")
plt.rcParams["axes.unicode_minus"] = False
```
</details>

### ì½”ë“œíŒŒì¼ ëª©ì°¨ ë° ë‚´ìš©
<details>
<summary>ğŸ§‘â€ğŸ’»listğŸ§‘â€ğŸ’»</summary>


### ì „ì²´ ì½”ë“œ íŒŒì¼

- 00_basics
  - [00_íŒŒì´ì¬_ê¸°ì´ˆ.ipynb](/code/00_basics/00_íŒŒì´ì¬_ê¸°ì´ˆ.ipynb)
      -  íŒŒì´ì¬ìœ¼ë¡œ í•  ìˆ˜ ìˆëŠ” ì¼
      -  íŒŒì´ì¬ ì— ì í•©í•˜ì§€ ì•Šì€ ì¼
      -  ìŠ¤ë„¤ì´í¬ ì¼€ì´ìŠ¤ì™€, ìºë©€ ì¼€ì´ìŠ¤
      -  ë¦¬ìŠ¤íŠ¸ì™€ ë°°ì—´ì˜ ì°¨ì´
      -  ì‹¤ìˆ˜ì™€ ì •ìˆ˜ì˜ ë‚œìˆ˜ ìƒì„± with numpy
      -  `np.where(a, b, c)`
  - [01_ì„ í˜•ê³¼_ë¹„ì„ í˜•.ipynb](/code/00_basics/01_ì„ í˜•ê³¼_ë¹„ì„ í˜•.ipynb)
  - [02_ë„í•¨ìˆ˜_ê³„ì‚°.ipynb](/code/00_basics/02_ë„í•¨ìˆ˜_ê³„ì‚°.ipynb)
      -  Gradient
  - [03_í†µê³„.ipynb](/code/00_basics/03_í†µê³„.ipynb)
      -  í†µê³„ì™€ ë°ì´í„° ë¶„ì„ì˜ ê¸°ì´ˆ ê°œë…
      -  ì •ê·œ ë¶„í¬ (Normal Distribution)
      -  í‘œì¤€í™” (Standardization)
      -  ê°€ì„¤(Hypothesis) ê²€ì •
      -  ë§Œì•½ ì •ê·œë¶„í¬ë¥¼ ë”°ë¥´ì§€ ì•Šì„ ë•Œ
      -  íŒŒì´ì¬ ì½”ë“œ
  - [04_ë²¡í„°í™”.ipynb](/code/00_basics/04_ë²¡í„°í™”.ipynb)
      -  ë²¡í„°ë¼ì´ì œì´ì…˜
      -  ì½”ì‚¬ì¸ ê±°ë¦¬
      -  CountVectorizer, TfidfVectorizer
  - [05_í† í°í™”.ipynb](/code/00_basics/05_í† í°í™”.ipynb)
      -  í† í¬ë‚˜ì´ì œì´ì…˜ (í† í°í™” : Tokenizaiton)
      -  IMDBë¥¼ ì´ìš©í•œ ì˜í™”í‰
  - [06_ê³µë¶„ì‚°ê³¼_ìƒê´€ê³„ìˆ˜.ipynb](/code/00_basics/06_ê³µë¶„ì‚°ê³¼_ìƒê´€ê³„ìˆ˜.ipynb)
      -  í†µê³„ì  ìˆ˜ì¹˜
      -  ê³µë¶„ì‚°
      -  í‘œì¤€ í¸ì°¨ ( std : standard deviation )
      -  Correlation
  - [07_data_ìœ í˜•.ipynb](/code/00_basics/07_data_ìœ í˜•.ipynb)
      -  ì •ëŸ‰ì  ë°ì´í„° (Quantitative Data)
      -  ì§ˆì  ë°ì´í„° (Qualitative Data)
      -  ì‹œê³„ì—´ ë° ê³µê°„ ë°ì´í„° (Temporal and Spatial Data)
      -  ë¯¸ë””ì–´ ë° ì„¼ì„œ ë°ì´í„° (Media and Sensor Data)
      -  êµ¬ì¡° ë° ê´€ê³„ ë°ì´í„° (Structured and Relational Data)
      -  í–‰ë™ ë° í™œë™ ë°ì´í„° (Behavioral and Activity Data)
      -  ë¶€ê°€ ë° ì„¤ëª… ë°ì´í„° (Supplementary and Descriptive Data)
      -  ë³µí•© ë° ì‹¤ì‹œê°„ ë°ì´í„° (Composite and Real-time Data)
      -  ì´ìƒ ë° íŠ¹ì´ ë°ì´í„° (Anomalous and Atypical Data)
      -  ì„ë² ë””ë“œ ë° íŠ¸ëœì­ì…˜ ë°ì´í„° (Embedded and Transactional Data)
      -  íš¡ë‹¨ë©´ ë° ì¢…ë‹¨ ë°ì´í„° (Cross-sectional and Longitudinal Data)
  - [08_Confusion_Matrix.ipynb](/code/00_basics/08_Confusion_Matrix.ipynb)
      -  Precision ê³¼ recall ì„ ë´ì•¼í•œë‹¤.
- 01_machinelearing
  - [01_ìƒê´€ê³¼_íšŒê·€.ipynb](/code/01_machinelearing/01_ìƒê´€ê³¼_íšŒê·€.ipynb)
      -  ìƒê´€ê³„ìˆ˜ (Correlation Coefficient)
      -  íšŒê·€ ê³„ìˆ˜ (Regression Coefficient)
      -  ìƒê´€ê³¼ íšŒê·€ì˜ ì°¨ì´
      -  ê²°ì • ê³„ìˆ˜ $R^2$
      -  ì˜¤ì°¨ì˜ ì¢…ë¥˜
      -  ì˜ˆì‹œ
  - [02_êµì°¨ê²€ì¦.ipynb](/code/01_machinelearing/02_êµì°¨ê²€ì¦.ipynb)
      -  êµì°¨ê²€ì¦(cross validation)
  - [03_GridSearch.ipynb](/code/01_machinelearing/03_GridSearch.ipynb)
      -  ê·¸ë¦¬ë“œ ì„œì¹˜(Grid Search)
      -  RandomizedSearchCV
  - [04_Feature_Importance.ipynb](/code/01_machinelearing/04_Feature_Importance.ipynb)
      -  feature importance
      -  ëœë¤ í¬ë ˆìŠ¤íŠ¸ ë° ë””ì‹œì „ íŠ¸ë¦¬ë¥¼ ì´ìš©í•´ì„œ ì •í™•ë„ êµ¬í•´ë³´ê¸°
      -  ëœë¤ í¬ë ˆìŠ¤íŠ¸ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ í”¼ì³ë¶€í„° í•˜ë‚˜ì”© ì¶”ê°€í•´ì„œ ë¹„êµí•´ ë³´ê¸°
  - [05_PCA_ì£¼ì„±ë¶„ë¶„ì„.ipynb](/code/01_machinelearing/05_PCA_ì£¼ì„±ë¶„ë¶„ì„.ipynb)
      -  ì£¼ì„±ë¶„ ë¶„ì„ (Principal Component Analysis, PCA)
      -  ìŠ¤ì¼€ì¼ë§ê³¼ pca
      -  Breast Cancer dataset
      -  ë°ì´í„° ìŠ¤ì¼€ì¼ë§
      -  PCA
      -  Digit dataset
      -  PCA
  - [06_knn.ipynb](/code/01_machinelearing/06_knn.ipynb)
      -  [KNN](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) (K-Neighbors-Classifier)
      -  knn íŒŒë¼ë¯¸í„° (scikit-learn)
      -  KNNì—ì„œì˜ ìµœì ì˜ Kê°’ ì°¾ê¸°
      -  ì ë‹¹í•œ kê°’ êµ¬í•˜ê¸° with êµì°¨ ê²€ì¦
  - [07_decision_tree.ipynb](/code/01_machinelearing/07_decision_tree.ipynb)
      -  Decision Tree (DecisionTreeClassifier)
      -  ë¶ˆìˆœë„
      -  ë¶„ë¥˜ vs íšŒê·€ : DecisionTreeClassifier vs DecisionTreeRegressor
  - [08_SVM.ipynb](/code/01_machinelearing/08_SVM.ipynb)
      -  SVM (Support Vector Machine)
      -  ì£¼ìš” í‚¤ì›Œë“œ
  - [09_ensemble.ipynb](/code/01_machinelearing/09_ensemble.ipynb)
      -  Ensemble
      -  Bagging (Bootstrap Aggragating)
      -  Bagging : Random Forest
      -  Bagging : Random Forest (Grid Search)
      -  Boosting
      -  ì¢…ë¥˜
      -  Boosting : AdaBoost
      -  Gradient Boosting
      -  Gradient Boosting : AdaBoost
      -  Gradient Boosting : XGBoost
  - [10_íšŒê·€_ì˜ˆì‹œ.ipynb](/code/01_machinelearing/10_íšŒê·€_ì˜ˆì‹œ.ipynb)
      -  ë°ì´í„° ë¡œë“œ
      -  ê²°ì¸¡í™•ì¸ (missingno as msno)
      -  ë°ì´í„° ìŠ¤í”Œë¦¿
      -  ìƒê´€ ê³„ìˆ˜
      -  ë°ì´í„° ìŠ¤ì¼€ì¼ë§
      -  Logistic Regression
      -  SVR
      -  K-NN Regressor
      -  Decision Tree Regressor
      -  Random Forest Regressor
      -  XGBoost Regressor
      -  ì˜¤ë‹µ í™•ì¸
  - [11_ë¶„ë¥˜_ì˜ˆì‹œ.ipynb](/code/01_machinelearing/11_ë¶„ë¥˜_ì˜ˆì‹œ.ipynb)
      -  ë°ì´í„° ë¡œë“œ
      -  ê²°ì¸¡í™•ì¸ (missingno as msno)
      -  ë°ì´í„° ìŠ¤í”Œë¦¿
      -  ìƒê´€ ê³„ìˆ˜
      -  ë°ì´í„° ìŠ¤ì¼€ì¼ë§
      -  Logistic Regression(ë¶„ë¥˜ì— ì´ìš©)
      -  SVC
      -  K-NN Classifier
      -  Decision Tree Classifier
      -  Random Forest Classifier
      -  XGBoost Classifier
      -  ì˜¤ë‹µ í™•ì¸
  - [12_Scaling.ipynb](/code/01_machinelearing/12_Scaling.ipynb)
- 02_DeepLearning
  - [01_deep_learning.ipynb](/code/02_DeepLearning/01_deep_learning.ipynb)
      -  ë”¥ëŸ¬ë‹
      -  ë”¥ëŸ¬ë‹ ì¢…ë¥˜
      -  ë”¥ëŸ¬ë‹ì˜ êµ¬ì¡°
      -  ë‹¨ì¸µ í¼ì…‰íŠ¸ë¡  ë° ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡ 
      -  ì¸ê³µ ì‹ ê²½ë§ì˜ í”„ë¡œì„¸ìŠ¤
      -  ì„ í˜• íšŒê·€ ëª¨í˜•ê³¼ ì‹ ê²½ë§ ëª¨ë¸ì˜ ì°¨ì´
      -  ì¶œë ¥ ë…¸ë“œì˜ ìˆ˜
  - [02_í™œì„±í™”_í•¨ìˆ˜.ipynb](/code/02_DeepLearning/02_í™œì„±í™”_í•¨ìˆ˜.ipynb)
      -  í™œì„±í™” í•¨ìˆ˜
      -  **Sigmoid (ì‹œê·¸ëª¨ì´ë“œ) í•¨ìˆ˜**:
      -  **Tanh (í•˜ì´í¼ë³¼ë¦­ íƒ„ì  íŠ¸) í•¨ìˆ˜**:
      -  **ReLU (Rectified Linear Unit) í•¨ìˆ˜**:
      -  **Leaky ReLU í•¨ìˆ˜**:
      -  **ELU (Exponential Linear Unit) í•¨ìˆ˜**:
      -  **SoftPlus í•¨ìˆ˜**:
      -  **GeLU (Gaussian Error Linear Unit) í•¨ìˆ˜**:
  - [03_ë¹„ìš©í•¨ìˆ˜.ipynb](/code/02_DeepLearning/03_ë¹„ìš©í•¨ìˆ˜.ipynb)
      -  ë¹„ìš©í•¨ìˆ˜
      -  íšŒê·€ ë¬¸ì œ
      -  ë¶„ë¥˜ ë¬¸ì œ
      -  ë¹„ìš©í•¨ìˆ˜ ì˜ˆì œ : íšŒê·€ ë¬¸ì œ
      -  ë¹„ìš©í•¨ìˆ˜ ì˜ˆì œ : ë¶„ë¥˜ ë¬¸ì œ
  - [04_ì—­ì „íŒŒ.ipynb](/code/02_DeepLearning/04_ì—­ì „íŒŒ.ipynb)
      -  ì—­ì „íŒŒ (Back Propagation)
      -  ì²´ì¸ ë£°
  - [05_ì˜µí‹°ë§ˆì´ì €.ipynb](/code/02_DeepLearning/05_ì˜µí‹°ë§ˆì´ì €.ipynb)
      -  Optimizer (ìˆ˜ì¹˜ ìµœì í™” ì•Œê³ ë¦¬ì¦˜)
      -  ê¸°ë³¸ ì´ë¡  : ê²½ì‚¬ í•˜ê°•ë²•(Gradient Descent)
      -  íƒìƒ‰ ë°©í–¥ ê¸°ë°˜ ì•Œê³ ë¦¬ì¦˜
      -  í•™ìŠµë¥  ê¸°ë°˜ ì•Œê³ ë¦¬ì¦˜
      -  ë‹¤ì–‘í•œ ì˜µí‹°ë§ˆì´ì € ì˜ˆì œ(torch)
  - [06_ë‹¤ì–‘í•œ_ë°ì´í„°.ipynb](/code/02_DeepLearning/06_ë‹¤ì–‘í•œ_ë°ì´í„°.ipynb)
      -  sklearn datasets
      -  tensorflow datasets
      -  seaborn datasets
      -  torchvision datasets
      -  cancer ë°ì´í„°
      -  Digits ë°ì´í„°
      -  MNIST ë°ì´í„°
      -  Iris dataset
      -  wine í’ˆì§ˆ(quality) ë°ì´í„°
      -  ë‹¤ì¤‘ ë¶„ë¥˜
  - [07_ë‹¤ì–‘í•œ_ê¸°ë²•ë“¤.ipynb](/code/02_DeepLearning/07_ë‹¤ì–‘í•œ_ê¸°ë²•ë“¤.ipynb)
      -  ë”¥ëŸ¬ë‹ ê°„ë‹¨í•œ ì¸µ ìŒ“ê¸°
      -  ì½œë°±
      -  EarlyStopping
      -  ê²°ê³¼ í™•ì¸
      -  ê³¼ì í•© ì‹œì‘ì  í™•ì¸
  - [08_ë‹¤ì–‘í•œ_ë¬¸ì œë“¤.ipynb](/code/02_DeepLearning/08_ë‹¤ì–‘í•œ_ë¬¸ì œë“¤.ipynb)
      -  ê²½ì‚¬ ì†Œì‹¤ (gradient vanishing)
      -  ë°ë“œ ë ë£¨ ë¬¸ì œ
      -  ê³¼ì í•© (Overfitting)
      -  ê³¼ì í•© í•´ê²°ì±…
      -  ì´ˆê¸° ê°€ì¤‘ì¹˜ ë¬¸ì œ(Weight Initialization Problem)
  - [09_CNN.ipynb](/code/02_DeepLearning/09_CNN.ipynb)
      -  CNN (Convolutional Neural Networks)
      -  ê³µê°„ ì •ë³´ ì¶”ì¶œ(Spatial)
      -  íŒ¨ë”©
      -  í’€ë§
      -  CNNì˜ í•™ìŠµ ê³¼ì •
      -  CNNì˜ í‚¤ì›Œë“œ
      -  Cifar10 ë°ì´í„°
      -  mnist ë°ì´í„°
  - [10_RNN.ipynb](/code/02_DeepLearning/10_RNN.ipynb)
      -  RNN(Reccurent Neural Networks)
      -  ì‹œí€€ìŠ¤ ë°ì´í„°
      -  RNNê³¼ FNN ëª¨ë¸ì˜ ì°¨ì´ì 
      -  RNNì„ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ ë¶„ì„
      -  ì‹œì‘ í† í° ë° ì¢…ë£Œ í† í°
      -  RNN ìˆœì„œ
      -  Return Sequence True íŒŒë¼ë¯¸í„°
      -  imdb data ì‹¤ìŠµ(return_seq_true with concat)
      -  imdb data ì‹¤ìŠµ(return_seq_true with mean)
  - [11_LSTM.ipynb](/code/02_DeepLearning/11_LSTM.ipynb)
      -  LSTM
      -  ê¸°ì–µ ì…€ ($C_t$)
      -  ê¸°ì–µ ì…€ì˜ ì—…ë°ì´íŠ¸
      -  ê¸°ì–µ ì…€(Memory Cell)
      -  Gate
      -  GRU(Gated Recurrent Unit)
      -  imdb ì‹¤ìŠµ
      -  bidirectional ë° stacked bidirectional
  - [12_AutoEncoder.ipynb](/code/02_DeepLearning/12_AutoEncoder.ipynb)
      -  AutoEncoder
      -  Encoder
      -  Latent Space(Code or z)
      -  Decoder
      -  Loss
      -  AE ì‘ìš©
      -  Mnist dataë¥¼ ì´ìš©í•œ AE
      -  AE ë¥¼ ì´ìš©í•œ ë°ì´í„° ì¦ê°•
- 03_DeepLearning_ê¸°ë²•ë“¤
  - [00_ë‹¤ì–‘í•œ_ë”¥ëŸ¬ë‹_ê¸°ë²•.ipynb](/code/03_DeepLearning_ê¸°ë²•ë“¤/00_ë‹¤ì–‘í•œ_ë”¥ëŸ¬ë‹_ê¸°ë²•.ipynb)
      -  SoftMax í•¨ìˆ˜
      -  BatchNormalization
      -  EarlyStopping
      -  Dropout
      -  Learning Rate Scheduler
      -  Data Augmentation
      -  L2 Regularization
      -  Model Checkpoint
      -  Early Learning Rate Scheduler
      -  Gradient Clipping
      -  Transfer Learning(ì „ì´ í•™ìŠµ)
      -  Attention Mechanism(ì–´í…ì…˜)
  - [01_ReceptiveField.ipynb](/code/03_DeepLearning_ê¸°ë²•ë“¤/01_ReceptiveField.ipynb)
      -  ìˆ˜ìš© ì˜ì—­
- 04_time_series
  - [01_time_series.ipynb](/code/04_time_series/01_time_series.ipynb)
      -  ì‹œê³„ì—´ ë°ì´í„°
      -  ë‹¤ë³€ëŸ‰ê³¼ ë‹¨ë³€ëŸ‰
      -  ì‹œê°„ ì¢…ì†ì„± Time Dependence
      -  ì‹œê³„ì—´ íŠ¹ì„±
      -  **ì •ìƒì„±**
  - [02_ARIMA_ë¶„ì„.ipynb](/code/04_time_series/02_ARIMA_ë¶„ì„.ipynb)
      -  ARIMA
      -  ìê¸°íšŒê·€ AR(auto regressive)
      -  ì°¨ë¶„ (**integrated**)
      -  ì´ë™ í‰ê· (Moving Average) - q
      -  ìê¸° ìƒê´€ì„± í™•ì¸ (Autocorrelation)
      -  Augmented Dickey-Fuller ë¥¼ ì´ìš©í•œ ì •ìƒì„± ê²€ì •
      -  ì°¨ë¶„ì— ëŒ€í•œ ADF
      -  statsmodels
  - [03_rag_feature.ipynb](/code/04_time_series/03_rag_feature.ipynb)
      -  Lag Feature (ì§€ì—° í”¼ì³)
      -  ì´ë™í‰ê· ì„ 
      -  regplot(íšŒê·€ì„ )
  - [05_trend.ipynb](/code/04_time_series/05_trend.ipynb)
      -  ë‹¤í•­ íŠ¹ì„±
      -  Moving Average Plots
      -  íŠ¸ë Œë“œ ì˜ˆì¸¡ (Trend, ì¶”ì„¸)
      -  ì”ì°¨ ëª¨ë¸ë§
      -  ì„±ëŠ¥ í‰ê°€
      -  ì§€ì—° í”¼ì³ ë° ì´ë™ í‰ê·  ìƒì„±
      -  ëª¨ë¸ ì‹œê°í™”
      -  example
      -  í•¨ìˆ˜ì •ì˜
      -  ì „ì²˜ë¦¬
  - [06_Cycles.ipynb](/code/04_time_series/06_Cycles.ipynb)
      -  Serial Dependence
      -  Cycles(Serial Dependence ì„ ë‚˜íƒ€ë‚´ëŠ” ì¼ë°˜ì ì¸ ë°©ë²•)
      -  Lagged Series and Lag plots
  - [07_seasonal.ipynb](/code/04_time_series/07_seasonal.ipynb)
      -  Seasonality
      -  ê³„ì ˆì„± í™•ì¸
      -  ì£¼ê°€ ì˜ˆì¸¡ ëª¨ë¸ ë° ì‹œê°í™”
      -  ì§€ìˆ˜ ë³€í™”ìœ¨ ë¶„ì„ ë° ì£¼ê¸°ì„± ì‹œê°í™”
      -  ê³„ì ˆì„± í”Œë¡¯(seasonal_plot)ê³¼ ì£¼ê¸°ë„(Periodogram)
      -  `scipy.signal.periodogram`
      -  ì£¼ê°€ ì˜ˆì¸¡ëª¨ë¸ (ì£¼ê¸°í•™ìŠµ)
  - [08_Hybrid_model.ipynb](/code/04_time_series/08_Hybrid_model.ipynb)
      -  Hybrid Model
      -  **Components and Residuals**
      -  Hybrid Forecasting with Residuals(ì”ì°¨ë¥¼ ì‚¬ìš©í•œ ë³µí•© ì˜ˆì¸¡)
      -  Hybrids ì•Œê³ ë¦¬ì¦˜ ë””ìì¸í•˜ê¸°
      -  í”¼ì³ ë³€í™˜ ì•Œê³ ë¦¬ì¦˜ 1 : Linear Regression
      -  íƒ€ê²Ÿ ë³€í™˜ ì•Œê³ ë¦¬ì¦˜ 2 : Tree ëª¨ë¸ ì¢…ë¥˜.
      -  í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ (Linear Regression + DecisionTreeRegressor ì˜ ì”ì°¨ )
      -  íŠ¸ëœë“œ(ë‹¤í•­íŠ¹ì„±)ë¥¼ ê³ ë ¤í•˜ì—¬ ì”ì°¨ì™€ í•¨ê»˜ í•™ìŠµí•˜ê¸°
  - [09_Forecast_stratagy.ipynb](/code/04_time_series/09_Forecast_stratagy.ipynb)
      -  ì˜ˆì¸¡ ëª¨ë¸ ì •ì˜í•˜ê¸°
      -  ì˜ˆì¸¡ ê¸°ì› (forecast origin)
      -  **forecast horizon**
      -  ìš©ì–´ì •ë¦¬
      -  ë©€í‹° ìŠ¤í… ì˜ˆì¸¡ ì „ëµ!
- 05_sequence
  - [01_Sequence.ipynb](/code/05_sequence/01_Sequence.ipynb)
      -  í¬ë¡¤ë§
      -  ë¶ˆëŸ¬ì˜¤ê¸°
      -  ê°€ê²© ë°ì´í„° íƒ€ì… ë³€ê²½
      -  ë‚ ì§œ ë°ì´í„° íƒ€ì… ë³€ê²½
      -  ê²°ì¸¡ í™•ì¸
      -  ë°ì´í„° ì •ë³´ í™•ì¸(ê³ ìœ³ê°’)
      -  ìƒê´€ê´€ê³„ ë¶„ì„
      -  ë¶„í¬ í™•ì¸
      -  ë‹¤ë³€ëŸ‰ ë¶„ì„ - ì‚°ì ë„ í–‰ë ¬
  - [02_Sequence_ëª¨ë¸ë§.ipynb](/code/05_sequence/02_Sequence_ëª¨ë¸ë§.ipynb)
      -  Sequence ëª¨ë¸ë§
      -  ì „ì²˜ë¦¬
      -  ëª¨ë¸ ì„¤ê³„ ë°‘ êµ¬ì¶•
      -  ì˜ˆì¸¡ ë° í‰ê°€
  - [03_word_embed_cluster.ipynb](/code/05_sequence/03_word_embed_cluster.ipynb)
      -  ì „ì²˜ë¦¬
      -  **Tf-idf** <br>
      -  **Word2Vec**
      -  **FastText**
- 06_visualization
  - [00_sns_ì‹œê°í™”ì½”ë“œ.ipynb](/code/06_visualization/00_sns_ì‹œê°í™”ì½”ë“œ.ipynb)
      -  ì—¬ìœ  ìˆì„ ë•Œ ë°°ìš°ë©´ ì¢‹ì€ ê²ƒ
      -  ì¹´í†  ê·¸ë¨
      -  Matplotlib ì‹œê°í™” all in one
      -  ë¼ì¸ ê·¸ë˜í”„
      -  ì‚°ì ë„
      -  ë°” ê·¸ë˜í”„
      -  íˆìŠ¤í† ê·¸ë¨
      -  ìœ¡ê° íˆìŠ¤í† ê·¸ë¨(hexbin)
      -  ë°•ìŠ¤, ë°”ì´ì˜¬ë¦° í”Œë¡¯
      -  ìƒ‰ìƒ ì„ íƒí•˜ê¸°
      -  íŒŒì¼ì €ì¥
  - [01_PCA_ì‹œê°í™”.ipynb](/code/06_visualization/01_PCA_ì‹œê°í™”.ipynb)
      -  pca ì‹œê°í™”
  - [02_ì§€ë„ ì‹œê°í™”(folium).ipynb](/code/06_visualization/02_ì§€ë„ ì‹œê°í™”(folium).ipynb)
      -  ë°ì´í„°ì—ì„œ ì§€ë„ ì‹œê°í™” ë° json ë‹¤ë£¨ê¸°
      -  ì§€ë„ ì‹œê°í™”
  - [03_boxplots.ipynb](/code/06_visualization/03_boxplots.ipynb)
      -  ì‚¬ë¶„ìœ„ ê°’
      -  IQR ê³„ì‚°í•˜ê¸°
      -  boxplots
  - [04_cv2_ê·¸ë¦¼ê·¸ë¦¬ê¸°.ipynb](/code/06_visualization/04_cv2_ê·¸ë¦¼ê·¸ë¦¬ê¸°.ipynb)
      -  cv2 ê·¸ë¦¼ê·¸ë¦¬ê¸°
- 07_Pretrained_CNN
  - [00_img_prep.ipynb](/code/07_Pretrained_CNN/00_img_prep.ipynb)
      -  ì‚¬ì§„ ë¶ˆëŸ¬ì˜¤ê¸°
      -  ì´ë¯¸ì§€ ê°€ë¡œ ì„¸ë¡œ ë§ì¶”ê¸° : íŒ¨ë”©
      -  ì´ë¯¸ì§€ ê°€ë¡œ ì„¸ë¡œ ë§ì¶”ê¸° : íŒ¨ë”©
      -  ì›Œí•‘
  - [01_img_featuremap.ipynb](/code/07_Pretrained_CNN/01_img_featuremap.ipynb)
      -  íŠ¹ì„± ë§µ í™•ì¸í•˜ê¸°
  - [02_LeNet.ipynb](/code/07_Pretrained_CNN/02_LeNet.ipynb)
      -  LeNet êµ¬ì¡°
      -  CNN ì˜ 1 by 1 í•„í„°
      -  lenet ì‹¤ìŠµ
  - [03_AlexNet.ipynb](/code/07_Pretrained_CNN/03_AlexNet.ipynb)
      -  alexnet
  - [04_VGG16.ipynb](/code/07_Pretrained_CNN/04_VGG16.ipynb)
      -  feature map
      -  ì‚¬ì „ í•™ìŠµ ëª¨í˜•ì„ í†µí•œ ì´ë¯¸ì§€ ë¶„ë¥˜ - VGG16
  - [05_inception(ggl)Net.ipynb](/code/07_Pretrained_CNN/05_inception(ggl)Net.ipynb)
      -  Inception Net
      -  Inception Net êµ¬ì¡°
      -  ì¸ì…‰ì…˜ ëª¨ë“ˆ êµ¬ì¡° í™•ì¸
      -  inception net + ë¨¸ì‹ ëŸ¬ë‹ ë¶„ë¥˜ ì•Œê³ ë¦¬ì¦˜ ì ìš©
  - [06_ResNet.ipynb](/code/07_Pretrained_CNN/06_ResNet.ipynb)
      -  Residual Block
      -  Skip Connection (ì…ë ¥ê°’ ì„ ì¶œë ¥ì— ë”í•˜ì—¬ ì „ë‹¬) ì˜ íš¨ê³¼
      -  ResNet ëª¨ë¸ í•™ìŠµ ê³¼ì •
      -  ResNet í”„ë¦¬ íŠ¸ë ˆì¸ë“œ ëª¨ë¸ ì´ìš©í•˜ê¸°
  - [07_mobile_Net.ipynb](/code/07_Pretrained_CNN/07_mobile_Net.ipynb)
      -  Mobile Net
      -  Depthwise Separable Convolution
      -  PointWise Convolution
      -  MoblieNet Pretrained Model
  - [08_DenseNet.ipynb](/code/07_Pretrained_CNN/08_DenseNet.ipynb)
      -  DenseNet
  - [09_EfficientNet.ipynb](/code/07_Pretrained_CNN/09_EfficientNet.ipynb)
      -  EfficientNet
  - [10_cnn_transfer_learning.ipynb](/code/07_Pretrained_CNN/10_cnn_transfer_learning.ipynb)
      -  Pretrained ëª¨ë¸ with ë¨¸ì‹ ëŸ¬ë‹
      -  ë¶„ë¥˜ ì•Œê³ ë¦¬ì¦˜ ì—°ê²° ë° ì˜ˆì¸¡
      -  íŒŒì¸ íŠœë‹
- 08_pretrained_RNN
  - [01_time_rnn.ipynb](/code/08_pretrained_RNN/01_time_rnn.ipynb)
      -  ARIMA ëª¨ë¸(pmdarima)
      -  ARIMA
      -  RNN ëª¨ë¸
      -  LSTM ëª¨ë¸
  - [02_LSTMëª¨ë¸_ì„¤ê³„.ipynb](/code/08_pretrained_RNN/02_LSTMëª¨ë¸_ì„¤ê³„.ipynb)
      -  LSTM ëª¨ë¸ ì„¤ê³„
  - [03_**Transformer**.ipynb](/code/08_pretrained_RNN/03_**Transformer**.ipynb)
      -  **Transformer**
      -  Transformer ì „ì²´ì ì¸ êµ¬ì„±
      -  Positional Encoding layer
      -  Self Attention layer
      -  Encoder Decoder Attention
      -  ì‹¤ìŠµ imdb
  - [04_BERTopic_En.ipynb](/code/08_pretrained_RNN/04_BERTopic_En.ipynb)
      -  Bert (Bidirectional Encoder Representations from Transformers)
      -  **BERTopic**
- 09_Object_Detection
  - [00_ReceptiveField.ipynb](/code/09_Object_Detection/00_ReceptiveField.ipynb)
      -  ìˆ˜ìš©ì˜ì—­
      -  ìˆ˜ìš©ì˜ì—­ë³„ í”¼ì³ í¬ê¸°
  - [01_Yolo.ipynb](/code/09_Object_Detection/01_Yolo.ipynb)
      -  YOLO (You Only Look Once)
      -  ë²„ì „ ë³„ ë¹„êµ
      -  YOLO with Robotics
  - [02_SSD.ipynb](/code/09_Object_Detection/02_SSD.ipynb)
      -  SSD (Single Shot MultiBox Detector)
      -  íŠ¹ì§•
      -  boxes
      -  í•™ìŠµ í”„ë¡œì„¸ìŠ¤ ìˆœì„œ
      -  ìš©ì–´ì •ë¦¬
      -  mAP (Mean Average Precision)
      -  None Max Suppression
      -  SSD example
  - [05_Semantic_Upsampling_Transposed.ipynb](/code/09_Object_Detection/05_Semantic_Upsampling_Transposed.ipynb)
  - [06_Semantic_Segmentation.ipynb](/code/09_Object_Detection/06_Semantic_Segmentation.ipynb)
  - [07_Semantic_Performance.ipynb](/code/09_Object_Detection/07_Semantic_Performance.ipynb)
  - [08_OD_RCNN_Offset.ipynb](/code/09_Object_Detection/08_OD_RCNN_Offset.ipynb)
- 10_ChatGPT_API
  - [00_ChatGPT_API_Chatbot.ipynb](/code/10_ChatGPT_API/00_ChatGPT_API_Chatbot.ipynb)
  - [01_ChatGPT_API.ipynb](/code/10_ChatGPT_API/01_ChatGPT_API.ipynb)
- 11_Private_chat
  - [00_GPT_2.ipynb](/code/11_Private_chat/00_GPT_2.ipynb)
  - [01_llama_3.ipynb](/code/11_Private_chat/01_llama_3.ipynb)
      -  Llama 3
- 12_ëª¨ë¸_ì‘ìš©
  - [00_NER.ipynb](/code/12_ëª¨ë¸_ì‘ìš©/00_NER.ipynb)
      -  NER ëª¨ë¸
  - [01_CNN_for_Text.ipynb](/code/12_ëª¨ë¸_ì‘ìš©/01_CNN_for_Text.ipynb)
  - [02_VQA.ipynb](/code/12_ëª¨ë¸_ì‘ìš©/02_VQA.ipynb)
      -  VQA :  <br>
- 13.ë°œí‘œ
  - [01_ë”¥ëŸ¬ë‹ì—ì„œ_ë°°ì¹˜_í¬ê¸°ì˜_ì—­í• .ipynb](/code/13.ë°œí‘œ/01_ë”¥ëŸ¬ë‹ì—ì„œ_ë°°ì¹˜_í¬ê¸°ì˜_ì—­í• .ipynb)
      -  ë°°ì¹˜ ì‚¬ì´ì¦ˆë€?
      -  ë°°ì¹˜ ì‚¬ì´ì¦ˆë³„ í•™ìŠµ
      -  ê²°ë¡ :
      -  ë°°ì¹˜ ì‚¬ì´ì¦ˆ ì„ íƒ ìš”ë ¹
  - [02_í…ì„œ_ìë£Œí˜•.ipynb](/code/13.ë°œí‘œ/02_í…ì„œ_ìë£Œí˜•.ipynb)
      -  Tensor ìë£Œí˜•
      -  í…ì„œ ì°¨ì›ë³„ ëª…ëª…ë²•
      -  íŒŒì´ í† ì¹˜ ì—ì„œì˜ ì‚¬ìš©
  - [03_ì˜µí‹°ë§ˆì´ì €_ë¹„êµ.ipynb](/code/13.ë°œí‘œ/03_ì˜µí‹°ë§ˆì´ì €_ë¹„êµ.ipynb)
      -  ì˜µí‹°ë§ˆì´ì € ë¹„êµ
  - [04_ì¸ê³µì§€ëŠ¥ì˜_í¸í–¥ì„±ê³¼_ì°¨ë³„.ipynb](/code/13.ë°œí‘œ/04_ì¸ê³µì§€ëŠ¥ì˜_í¸í–¥ì„±ê³¼_ì°¨ë³„.ipynb)
      -  ì¸ê³µì§€ëŠ¥ì˜ í¸í–¥ì„±ê³¼ ì°¨ë³„ë¬¸ì œ
      -  ì¢…ë¥˜
      -  ì›ì¸
      -  Ai ì°¨ë³„
  - [05_ì¸ê³µì§€ëŠ¥ì˜_ì°½ì˜ì„±ê³¼_ì €ì‘ê¶Œ.ipynb](/code/13.ë°œí‘œ/05_ì¸ê³µì§€ëŠ¥ì˜_ì°½ì˜ì„±ê³¼_ì €ì‘ê¶Œ.ipynb)
      -  ì°½ì˜ì„±
      -  ë…¼ì 
      -  ì°½ì˜ì„± ì‹œí—˜
      -  AI ë“œë¡ 
      -  ì €ì‘ê¶Œ
      -  Nara AI Film
      -  ê²°ë¡ 
  - [06_ë”¥ëŸ¬ë‹_ëª¨ë¸ì˜_í•´ì„ê°€ëŠ¥ì„±.ipynb](/code/13.ë°œí‘œ/06_ë”¥ëŸ¬ë‹_ëª¨ë¸ì˜_í•´ì„ê°€ëŠ¥ì„±.ipynb)
      -  ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ í•´ì„ ê°€ëŠ¥ì„±
      -  í•´ì„
  - [08_ë°ì´í„°_í™œìš©ê³¼_ê°œì¸ì •ë³´_ë³´í˜¸.ipynb](/code/13.ë°œí‘œ/08_ë°ì´í„°_í™œìš©ê³¼_ê°œì¸ì •ë³´_ë³´í˜¸.ipynb)
      -  ë°ì´í„° í™œìš©ê³¼ ê°œì¸ì •ë³´ ë³´í˜¸
      -  ë¹…ë°ì´í„°ë€
      -  ë°ì´í„° í™œìš©
      -  ê°œì¸ì •ë³´ ë³´í˜¸
      -  ê°œì¸ì •ë³´ ë³´í˜¸ ì¤‘ì‹¬ ì„¤ê³„ :
  - [09_í™œì„±í™”_í•¨ìˆ˜.ipynb](/code/13.ë°œí‘œ/09_í™œì„±í™”_í•¨ìˆ˜.ipynb)
      -  í™œì„±í™” í•¨ìˆ˜
      -  ì˜ë¯¸ì™€ ì—­í• 
      -  ì¢…ë¥˜
      -  ì„ íƒ ê¸°ì¤€
  - [10_ì¸ê³µì§€ëŠ¥ì˜_ìœ¤ë¦¬ì _ê³ ë ¤ì‚¬í•­.ipynb](/code/13.ë°œí‘œ/10_ì¸ê³µì§€ëŠ¥ì˜_ìœ¤ë¦¬ì _ê³ ë ¤ì‚¬í•­.ipynb)
  - [11_transformer.ipynb](/code/13.ë°œí‘œ/11_transformer.ipynb)
      -  Transformer
      -  ì–´í…ì…˜ ì‹œê°í™”
  - [12_alex_net.ipynb](/code/13.ë°œí‘œ/12_alex_net.ipynb)
      -  Alex Net
      -  êµ¬ì¡°
  - [7.02.VQA.ipynb](/code/13.ë°œí‘œ/7.02.VQA.ipynb)
- 14.Generative_Deep_Learning_2nd_ê³µë¶€ë‚´ìš©
  - [00_2.3_ë‹¤ì¸µ_í¼ì…‰íŠ¸ë¡ _êµ¬í˜„.ipynb](/code/14.Generative_Deep_Learning_2nd_ê³µë¶€ë‚´ìš©/00_2.3_ë‹¤ì¸µ_í¼ì…‰íŠ¸ë¡ _êµ¬í˜„.ipynb)
  - [01_2.4_í•©ì„±ê³±_ì‹ ê²½ë§.ipynb](/code/14.Generative_Deep_Learning_2nd_ê³µë¶€ë‚´ìš©/01_2.4_í•©ì„±ê³±_ì‹ ê²½ë§.ipynb)
  - [02_3._VAE_in_book_extra(faceA).ipynb](/code/14.Generative_Deep_Learning_2nd_ê³µë¶€ë‚´ìš©/02_3._VAE_in_book_extra(faceA).ipynb)
  - [03_3.1_VAE.ipynb](/code/14.Generative_Deep_Learning_2nd_ê³µë¶€ë‚´ìš©/03_3.1_VAE.ipynb)
      -  í•™ìŠµ ì¶œë ¥
  - [04_3.2_multivariable_normal_distribution.ipynb](/code/14.Generative_Deep_Learning_2nd_ê³µë¶€ë‚´ìš©/04_3.2_multivariable_normal_distribution.ipynb)
  - [05_3.2_VAE_in_book.ipynb](/code/14.Generative_Deep_Learning_2nd_ê³µë¶€ë‚´ìš©/05_3.2_VAE_in_book.ipynb)
  - [06_3.ì˜¤í† ì¸ì½”ë”.ipynb](/code/14.Generative_Deep_Learning_2nd_ê³µë¶€ë‚´ìš©/06_3.ì˜¤í† ì¸ì½”ë”.ipynb)
  - [07_GAN.ipynb](/code/14.Generative_Deep_Learning_2nd_ê³µë¶€ë‚´ìš©/07_GAN.ipynb)
  - [08_vae_done.ipynb](/code/14.Generative_Deep_Learning_2nd_ê³µë¶€ë‚´ìš©/08_vae_done.ipynb)
  - [09_WGAN_GP-gptmade.ipynb](/code/14.Generative_Deep_Learning_2nd_ê³µë¶€ë‚´ìš©/09_WGAN_GP-gptmade.ipynb)
  - [10_WGAN_GP.ipynb](/code/14.Generative_Deep_Learning_2nd_ê³µë¶€ë‚´ìš©/10_WGAN_GP.ipynb)


</details>

## AI study
- ### [Notion ì „ì²´ ë‚´ìš© ë§í¬](https://royal-offer-53a.notion.site/KDT-2024-05-2024-09-134f678f80468007b265d54d5952da14)
- ### [Notion ì •ë¦¬ ë‚´ìš© ë§í¬](https://royal-offer-53a.notion.site/KDT-2024-05-2024-09-10bf678f80468069b4e1e2f0a631131a)

## í”„ë¡œ ì íŠ¸ ì •ë¦¬ Git
- [project1](https://github.com/tommyjin2894/KDT_project1)
- [project2](https://github.com/tommyjin2894/KDT_project2)
- project3
    - [ì„œë¹„ìŠ¤](https://github.com/tommyjin2894/project_3_service)
    - [í›ˆë ¨ ë° ê²°ê³¼](https://github.com/tommyjin2894/project_3_git)

## ì•„ë˜ ë‚´ìš© ìš”ì•½ ëª©ì°¨
- [ë°ì´í„° ì „ì²˜ë¦¬ ë° ë¶„ì„ ë‹¨ê³„](https://github.com/tommyjin2894/ai_study?tab=readme-ov-file#%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%B2%98%EB%A6%AC-%EB%B0%8F-%EB%B6%84%EC%84%9D-%EB%8B%A8%EA%B3%84)
- [ë§ˆì´ë‹ ì•Œê³ ë¦¬ì¦˜](https://github.com/tommyjin2894/ai_study?tab=readme-ov-file#%EB%A7%88%EC%9D%B4%EB%8B%9D-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98-1)
- [ìƒ˜í”Œë§ ê¸°ë²•](https://github.com/tommyjin2894/ai_study?tab=readme-ov-file#%EC%83%98%ED%94%8C%EB%A7%81-%EA%B8%B0%EB%B2%95)
- [ë”¥ëŸ¬ë‹](https://github.com/tommyjin2894/ai_study?tab=readme-ov-file#%EB%94%A5%EB%9F%AC%EB%8B%9D)
- [ëª¨ë¸ í‰ê°€](https://github.com/tommyjin2894/ai_study?tab=readme-ov-file#%EB%AA%A8%EB%8D%B8-%ED%8F%89%EA%B0%80)
- [ë¶„ë¥˜ ë¬¸ì œ](https://github.com/tommyjin2894/ai_study?tab=readme-ov-file#%EB%B6%84%EB%A5%98-%EB%AC%B8%EC%A0%9C)
- [íšŒê·€ ë¬¸ì œ](https://github.com/tommyjin2894/ai_study?tab=readme-ov-file#%ED%9A%8C%EA%B7%80-%EB%AC%B8%EC%A0%9C)
- [ì‹œê³„ì—´ ë°ì´í„°](https://github.com/tommyjin2894/ai_study?tab=readme-ov-file#%EC%8B%9C%EA%B3%84%EC%97%B4-%EB%8D%B0%EC%9D%B4%ED%84%B0)
## ë‚´ìš© ìš”ì•½ ì •ë¦¬


### ë°ì´í„° ì „ì²˜ë¦¬ ë° ë¶„ì„ ë‹¨ê³„
1. **ë°ì´í„° íƒìƒ‰**:
   - ë‹¤ì–‘í•œ ë°ì´í„°ì…‹(ì˜ˆ: ë¶€ì‚° ì§‘ê°’, Iris, HR, Titanic ë°ì´í„°)ì„ ë¶„ì„í•  ë•Œ, ë°ì´í„°ì˜ êµ¬ì¡°ì™€ íŠ¹ì„±ì„ ë¨¼ì € ì´í•´.
   - ë°ì´í„°ì˜ ê²°ì¸¡ ê°’, ì´ìƒì¹˜, ë³€ìˆ˜ì˜ ì¢…ë¥˜ ë“±ì„ íŒŒì•….

2. **ê²°ì¸¡ì¹˜ ì²˜ë¦¬**:
   - **Numerical ë°ì´í„°**: 
     - ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²•ì€ í‰ê· ì´ë‚˜ ì¤‘ì•™ê°’ìœ¼ë¡œ ê²°ì¸¡ì¹˜ë¥¼ ëŒ€ì²´í•˜ëŠ” ê²ƒ.
     - ë‹¤ë¥¸ íŠ¹ì„±ê³¼ì˜ ê´€ê³„ë¥¼ ë¶„ì„í•˜ì—¬ ë” ì í•©í•œ ê°’ì„ ì°¾ì•„ ì±„ìš¸ ìˆ˜ë„ ìˆë‹¤.
   - **Categorical ë°ì´í„°**:
     - ìƒˆë¡œìš´ ì¹´í…Œê³ ë¦¬ë¥¼ ë§Œë“¤ì–´ ê²°ì¸¡ì¹˜ë¥¼ ëŒ€ì²´í•  ìˆ˜ ìˆë‹¤.
     - ë‹¤ë¥¸ íŠ¹ì„±ê³¼ì˜ ê´€ê³„ë¥¼ ê³ ë ¤í•˜ì—¬ ê²°ì¸¡ì¹˜ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆë‹¤.

3. **Feature Engineering**:
   - ìƒˆë¡œìš´ íŠ¹ì„±ì„ ìƒì„±í•˜ì—¬ ë°ì´í„°ë¥¼ ë³€í™˜í•˜ê±°ë‚˜ ì°¨ì›ì„ ì¤„ì¼ ìˆ˜ ìˆë‹¤.
   - **Categorical ë³€ìˆ˜ ì²˜ë¦¬**:
     - **Nominal (ìˆœì„œ ì—†ìŒ)**: One-hot encodingì„ ì‚¬ìš©í•˜ê±°ë‚˜ ë°ì´í„° íƒ€ì…ì„ `categorical`ë¡œ ì§€ì •í•œë‹¤.
     - **Ordinal (ìˆœì„œ ìˆìŒ)**: ì´ëŸ¬í•œ ë³€ìˆ˜ëŠ” ìˆ«ì(ì˜ˆ: ìì—°ìˆ˜)ë¡œ ë³€í™˜í•˜ì—¬ ìˆœì„œë¥¼ ë°˜ì˜í•œë‹¤.

4. **ì´ìƒì¹˜ ì²˜ë¦¬**:
   - ê° íŠ¹ì„±ì— ëŒ€í•œ ê¹Šì€ ì´í•´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´ìƒì¹˜ì¸ì§€ íŒë‹¨í•œë‹¤.
   - ë‹¤ë¥¸ íŠ¹ì„±ê³¼ì˜ ê´€ê³„ë¥¼ ë¶„ì„í•˜ì—¬ ë°ì´í„°ê°€ ì‹¤ì œë¡œ ì´ìƒí•œì§€ í‰ê°€í•œë‹¤.

5. **ë°ì´í„° ì‹œê°í™”**:
   - Matplotlib, Seaborn ë“±ì„ ì‚¬ìš©í•´ ë°ì´í„°ë¥¼ ì‹œê°í™”.
   - ë°ì´í„°ì˜ íŒ¨í„´, ë¶„í¬, ê´€ê³„ ë“±ì„ ì´í•´í•˜ê¸° ìœ„í•˜ì—¬ ì ì ˆí•œ ê·¸ë˜í”„ì™€ ìƒ‰ìƒ ë“±ì„ ì„ íƒ.
   - $x$ì¶•, $y$ì¶• ë° ì œëª©ì„ ëª…í™•íˆ í‘œì‹œí•˜ê³ , í•„ìš”í•œ ê²½ìš° ì¶”ê°€ ì„¤ëª…ì„ ì‚½ì….

6. **ìƒê´€ê´€ê³„ ë¶„ì„**:
   - ë‘ ë³€ìˆ˜ ê°„ì˜ ê´€ê³„ë¥¼ ìˆ˜ì¹˜í™”.
   - **ìˆ˜ì¹˜í˜• ë°ì´í„°**: í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ë¥¼ ì‚¬ìš©.
   - **ìˆœì„œí˜• ë°ì´í„°**: ìŠ¤í”¼ì–´ë§Œ ìƒê´€ê³„ìˆ˜ë¥¼ ì‚¬ìš©.

7. **ìŠ¤ì¼€ì¼ë§**:
   - ë°ì´í„°ì˜ ë¶„í¬ ë²”ìœ„ë¥¼ ê· ì¼í•˜ê²Œ ë§ì¶¤.
   - **ë°©ë²•**: Min-Max ìŠ¤ì¼€ì¼ë§, Standard ìŠ¤ì¼€ì¼ë§, Robust ìŠ¤ì¼€ì¼ë§ ë“±.

8. **ì°¨ì› ì¶•ì†Œ**:
   - ì°¨ì›ì´ ë†’ì„ ê²½ìš°, ê³¼ì í•©ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ì°¨ì›ì„ ì¶•ì†Œ.
   - **ê¸°ë²•**: PCA, t-SNE ë“±. ëª¨ë¸ í•™ìŠµ ì „ ì •ë³´ ë³´ì¡´ì„ ìœ„í•´ ì°¨ì›ì„ ì¤„ì´ê±°ë‚˜ ë°ì´í„°ë¥¼ 2D/3Dë¡œ ì‹œê°í™”í•  ë•Œ ì‚¬ìš©.

**ì£¼ì˜ì‚¬í•­**: í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ì „ì²˜ë¦¬ëŠ” í›ˆë ¨ ë°ì´í„°ì—ì„œ ì–»ì€ ì •ë³´ë¥¼ ê¸°ì¤€ìœ¼ë¡œë§Œ ì´ë£¨ì–´ì ¸ì•¼ í•¨. ì´ëŠ” ë°ì´í„° ëˆ„ìˆ˜ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•œ ì¤‘ìš”í•œ ì›ì¹™.

### ë§ˆì´ë‹ ì•Œê³ ë¦¬ì¦˜
- ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸(ì§€ë„ í•™ìŠµ)   
    |ëª¨ë¸|ì´ë¦„|ì„¤ëª…|
    |---|---|---|
    |ë¶„ë¥˜|Decision Tree|íŠ¸ë¦¬êµ¬ì¡°ë¡œ ë°ì´í„°ë¥¼ ë¶„ë¥˜, ì¡°ê±´ ë¶„ê¸°|
    |-|Random Forest|ì•™ìƒë¸” ê¸°ë²•ì¤‘ baseline Bagging ì¤‘ í•˜ë‚˜ <br> ì—¬ëŸ¬ê°œì˜ DTë¡œ êµ¬ì„±|
    |-|KNN|ê°€ê¹Œìš´ K ê°œì˜ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê²°ì • <br> baseline L1 ë° L2 ê±°ë¦¬|
    |-|SVM|í´ë˜ìŠ¤ ê°„ì˜ ê²½ê³„ë¥¼ ìµœëŒ€í™”í•˜ì—¬ ì´ˆí‰ë©´ì„ ì°¾ëŠ”ë‹¤.|
    |íšŒê·€|Linear Regression|ì„ í˜• ê´€ê³„ ëª¨ë¸ë§|
    |-|Logistic Regression|ì´ì§„ ë¶„ë¥˜ë¥¼ ìœ„í•œ íšŒê·€ ë¶„ì„ ê¸°ë²•,<br> baseline í™•ë¥ ë¡œ ì¶œë ¥ê°’ì„ ë³€í™˜|
    |ì¸ê³µ ì‹ ê²½ë§|NN|ì—¬ëŸ¬ì¸µì˜ ë‰´ëŸ°|
    |ê¸°íƒ€|AdaBoost|ì•½í•œ í•™ìŠµê¸° x N = ê°•í•œ í•™ìŠµê¸°|
    |-|XGBoost|Gradient Boosting Machines ì˜ íš¨ìœ¨ì ì´ê³  ê°•ë ¥í•˜ê²Œ ê°œì„ |


- ë¹„ì§€ë„ í•™ìŠµ
    |ì¢…ë¥˜|ì´ë¦„|ì„¤ëª…|
    |-|-|-|
    |í´ëŸ¬ìŠ¤í„°ë§|k-means|ë¹„ìŠ·í•œ í¬ì¸íŠ¸ë¥¼ ê°€ê¹ê²Œ ìœ„ì¹˜|
    |-|ê³„ì¸µì  í´ëŸ¬ìŠ¤í„°ë§|íŠ¸ë¦¬ êµ¬ì¡°ë¡œ ì¡°ì§í™”|
    |ì—°ê´€ ê·œì¹™|Apriori ì•Œê³ ë¦¬ì¦˜|ìì£¼ ë°œìƒ í•˜ëŠ” ì—°ê´€ ì§‘í•©|
    |-|FP-Growth|Apriori ë³´ë‹¤ íš¨ìœ¨ì ì¸ |
    |ì°¨ì› ì¶•ì†Œ|PCA|ë°ì´í„°ë¥¼ ì••ì¶•, ì €ì°¨ì›ìœ¼ë¡œ|
    |-|t-SNE|2~3 ì°¨ì›ìœ¼ë¡œ ì‹œê°í™”, ë¹„ìŠ·í•œ ë°ì´í„° ê·¸ë£¹í™”|
        baseline í´ëŸ¬ìŠ¤í„°ë§ : ìœ ì‚¬ë„ ê¸°ì¤€ L1(manhatten), L2(Euclidean) ìœ¼ë¡œ êµ°ì§‘í™”


- ë‹¤ì–‘í•œ ê¸°ë²•
    |ì¢…ë¥˜|ì´ë¦„|ì„¤ëª…|
    |---|---|---|
    |ê¸°ë²•|K-fold êµì°¨ ê²€ì¦|ì ìˆ˜ í‰ê· |
    |-|Grid search|ëª¨ë“  ê²½ìš°ì˜ìˆ˜ë¥¼ ë³¸ë‹¤|
    |-|Randomized search|ëœë¤í•œ ê²½ìš°ì˜ìˆ˜ë¥¼ ë³¸ë‹¤|
    |ì•™ìƒë¸”|bagging<br> (bootstrap aggregating)|1. baseline N ê°œì˜ ìƒ˜í”Œì„ ë½‘ê¸°<br>->ì§‘ì–´ë„£ê³  N ê°œì˜ ìƒ˜í”Œì„ ë½‘ëŠ”ë‹¤. <br> 2. ì¤‘ë³µì´ ìƒê¸¸ ìˆ˜ ìˆìŒ|
    |-|Boosting|ì•½í•œ í•™ìŠµê¸° X N = ê°•í•œ í•™ìŠµê¸° <br>AdaBoost, XGBoost, Lgith GBM, Cat     Boost ë“±|
    |-|Stacking|ì—¬ëŸ¬ ê°œì˜ ê¸°ì´ˆëª¨ë¸ì˜ ì˜ˆì¸¡<br>ì¢…í•©í•˜ì—¬ ìƒˆë¡œìš´ ë©”íƒ€ëª¨ë¸ ìƒì„±|


- K-fold êµì°¨ ê²€ì¦
    - í›ˆë ¨ ë°ì´í„°ë¥¼ k ê°œë¡œ ë¶„í• í•´ ë²ˆê°ˆì•„ ê°€ë©´ì„œ í›ˆë ¨ í‰ê°€
      |í•™ìŠµ ëª¨ë¸|ë°ì´í„°1|ë°ì´í„°2|ë°ì´í„°3|ë°ì´í„°4|ë°ì´í„°5|
      | ---| --- | --- | --- | --- | --- |
      | í•™ìŠµ 1 | train | train | train | train | test |
      | í•™ìŠµ 2 | train | train | train | test | train |
      | í•™ìŠµ 3 | train | train | test | train | train |
      | í•™ìŠµ 4 | train | test | train | train | train |
      | í•™ìŠµ 5 | test | train | train | train | train |

### ìƒ˜í”Œë§ ê¸°ë²•

- ë°ì´í„° ë¶ˆê· í˜• ì„±ëŠ¥í‰ê°€
    - ë°ì´í„° ë¶ˆê· í˜• íŒë‹¨ê¸°ì¤€ : 30%
        - ë°ì´í„° ë¶ˆ ê· í˜•ì‹œ ë‹¤ì–‘í•œ ìƒ˜í”Œë§ ë° ë‹¤ì–‘í•œ metrics ì„¤ì •
          - ì •í™•ë„, ì •ë°€ë„, ì¬í˜„ìœ¨, F1 ìŠ¤ì½”ì–´, AUC-ROC,


-  ìƒ˜í”Œë§ ê¸°ë²•
    - ì„ì˜ ì¶”ì¶œ
    - ê³„í†µ ì¶”ì¶œ (ê³µì¥)
    - ì¸µí™” ì¶”ì¶œ (ë‚˜ì´ ë° ì„±ë³„ë³„ ì¶”ì¶œ)
    - êµ°ì§‘ ì¶”ì¶œ (ì „êµ­ -> ì„œìš¸)
    - ë‹¤ ë‹¨ê³„ ì¶”ì¶œ (ì „êµ­ -> ì„œìš¸ -> ë‚¨ì„±)
    - ë¹„ í™•ë¥ ì  ì¶”ì¶œ (ì„ì˜ ì¶”ì¶œ)
  
ì£¼ì˜ : í¸í–¥ì ì¸ ë°ì´í„°ê°€ ë˜ì§€ ì•Šê²Œ

### ë”¥ëŸ¬ë‹
- ì¢…ë¥˜
    |ì´ë¦„|íŠ¹ì§•|êµ¬ì¡°|
    |-|-|-|
    |ë‹¨ì¸µ í¼ì…‰íŠ¸ë¡ |XOR ë¬¸ì œì™€ ê°™ì€ ë¹„ì„ í˜• ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ì—†ìŒ<br>ì—­ì „íŒŒëŠ” ì¡´ì¬í•˜ì§€ ì•Šì•˜ë‹¤|ë‹¨ì¸µ êµ¬ì¡°|
    |ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡  (MLP)|ë²”ìš© ê·¼ì‚¬ê¸°:<br>ì¶©ë¶„íˆ í¬ê³  ë³µì¡í•œ ì–´ë– í•œ ë¬¸ì œë¼ë„ ì´ë¡ ì ìœ¼ë¡œ í•™ìŠµ ê°€ëŠ¥|ì…ë ¥ì¸µ, ì€ë‹‰ì¸µ(ë‹¤ìˆ˜), ì¶œë ¥ì¸µ|
    |CNN (Convolutional Neural Networks)|ê³µê°„ì  ê³„ì¸µ êµ¬ì¡°ë¥¼ í†µí•´ ì´ë¯¸ì§€ ë° ë¹„ë””ì˜¤ ë°ì´í„°ì˜ íŠ¹ì§• ì¶”ì¶œì— íƒì›”í•¨|Convolutional layer, Pooling layer, Fully Connected layer|
    |RNN (Recurrent Neural Networks)|ì‹œí€€ìŠ¤ ë°ì´í„° ì²˜ë¦¬ì— ê°•ì ,<br>ì‹œê³„ì—´ ë° ìì—°ì–´ ì²˜ë¦¬ì— ìœ ìš©|Recurrent êµ¬ì¡°, Hidden state vector|
    |LSTM (Long Short-Term Memory)|ì¥ê¸° ì˜ì¡´ì„± ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì„¤ê³„ë¨,<br>Forget-Input-Output Gate ë° Cell state(ê¸°ì–µ ì…€)ë¥¼ ì‚¬ìš©|LSTM Cell êµ¬ì¡°, Gates (Forget, Input, Output), Cell state|
    |GRU (Gated Recurrent Unit)|LSTMì˜ ê²½ëŸ‰í™”ëœ ë³€í˜•,<br>ë” ê°„ë‹¨í•œ êµ¬ì¡°ë¡œ ê¸°ì–µ ì…€ ì—†ì´ Gateë§Œ ì‚¬ìš©|GRU Cell êµ¬ì¡°, Update Gate, Reset Gate|
    |AutoEncoder|ë°ì´í„°ì˜ ì°¨ì›ì„ ì¶•ì†Œí•˜ê³  ì¬ìƒì„±í•˜ì—¬ ë°ì´í„° ì••ì¶• ë° ë…¸ì´ì¦ˆ ì œê±°,<br>íŠ¹ì„± í•™ìŠµì— ì‚¬ìš©ë¨|Encoder -> Latent Space(z) -> Decoder|
    |Transformer|Attention ë©”ì»¤ë‹ˆì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ì…ë ¥ ì‹œí€€ìŠ¤ì˜ ëª¨ë“  ìš”ì†Œë¥¼ ë™ì‹œì ìœ¼ë¡œ ì²˜ë¦¬,<br>ì¥ê¸° ì˜ì¡´ì„± ë¬¸ì œ í•´ê²°|Self-Attention Mechanism, Encoder-Decoder êµ¬ì¡°, Multi-Head Attention, Position-wise Feed-Forward Networks|
    |ResNet (Residual Networks)|Residual Blockì„ ì‚¬ìš©í•˜ì—¬ ë§¤ìš° ê¹Šì€ ì‹ ê²½ë§ì„ í•™ìŠµ,<br>Gradient Vanishing ë¬¸ì œ ì™„í™”|Residual Block, Skip Connections, Convolutional Layers|
    |EfficientNet|ëª¨ë¸ì˜ í¬ê¸°ì™€ ê³„ì‚° íš¨ìœ¨ì„±ì„ ì¡°ì •í•˜ê¸° ìœ„í•œ Compound Scaling ì‚¬ìš©,<br>ë†’ì€ ì„±ëŠ¥ê³¼ íš¨ìœ¨ì„± ì œê³µ|EfficientNet Blocks, Compound Scaling, Swish Activation Function|
    |VAE (Variational Autoencoder)|ì ì¬ ê³µê°„ì˜ í™•ë¥  ë¶„í¬ë¥¼ í•™ìŠµí•˜ì—¬ ìƒˆë¡œìš´ ìƒ˜í”Œì„ ìƒì„±,<br>ë°ì´í„°ì˜ í™•ë¥ ì  íŠ¹ì„±ì„ ëª¨ë¸ë§|Encoder, Latent Space (Probability Distribution), Decoder, Variational Objective|
    |GAN (Generative Adversarial Network)|ìƒì„±ìì™€ íŒë³„ì ê°„ì˜ ê²½ìŸì„ í†µí•´ ë°ì´í„° ìƒì„±,<br>ì´ë¯¸ì§€ ìƒì„±, ë°ì´í„° ì¦ê°• ë“±ì— ì‚¬ìš©|Generator, Discriminator, Adversarial Training|

- ë¹„ìš©í•¨ìˆ˜ ë° ì†ì‹¤í•¨ìˆ˜
    - ì†ì‹¤ í•¨ìˆ˜ : ë°ì´í„° í¬ì¸íŠ¸ í•˜ë‚˜ì— ëŒ€í•œ ì˜¤ì°¨ í•¨ìˆ˜
    - ë¹„ìš© í•¨ìˆ˜ : ì „ì²´ ë°ì´í„°ì— ëŒ€í•œ ì˜¤ì°¨ í•¨ìˆ˜

    |êµ¬ë¶„|ì´ë¦„|íŠ¹ì§•|êµ¬ì¡°|
    |-|-|-|-|
    |íšŒê·€ ë¬¸ì œ|ë‹¨ì¸µ í¼ì…‰íŠ¸ë¡ |XOR ê°™ì€ ë¹„ì„ í˜• ë¬¸ì œì— ëŒ€í•œ í•œê³„<br>ì—­ì „íŒŒëŠ” ì¡´ì¬í•˜ì§€ ì•Šì•˜ë‹¤|ë‹¨ì¸µ êµ¬ì¡°|
    |-|MSE|ì œê³±, ì´ìƒì¹˜ì— ë¯¼ê°|$\text{MSE} = \frac{1}{N} \sum_{i=1}^{N} (y_i - \hat{y}_i)^2$|
    |-|MAE|ì ˆëŒ€ ê°’, ì´ìƒì¹˜ì— ë‘”ê°|$\text{MSE} = \frac{1}{N} \sum_{i=1}^{N} \lvert y - \hat{y} \lvert$|
    |-|í—ˆë¸Œ ì†ì‹¤|MSE + MAE|MSE + MAE ì˜ êµ¬ì¡°|
    |-|ë¡œê·¸ ì½”ì‚¬ì¸ ìœ ì‚¬ë„|ì´ìƒì¹˜ì— ë§¤ìš° ê°•í•¨|$\log - \cosh = \frac{1}{N} \sum^{N}_{i = 1} \log({\cosh (\hat{y}-y)})$|
    |ë¶„ë¥˜ ë¬¸ì œ|Cross Entropy Error|ì´ì§„ ë¶„ë¥˜ : binary CEE<br>ë‹¤ì¤‘ ë¶„ë¥˜ : Categorical CEE|$CEE = -\sum_{k=1}^i t_k\text{log}\hat{y}$|
    |-|íŒì§€ ì†ì‹¤|SVM ì—ì„œ ì‚¬ìš©<br>ë§ˆì§„ ì˜¤ë¥˜ ìµœì†Œí™”||
    |-|ì œê³± íŒì§€ ì†ì‹¤|ì´ìƒì¹˜ì˜ ë¯¼ê°||
    |-|í¬ì¹¼ ì†ì‹¤|ì˜¤ë‹µì— ëŒ€í•œ ê°€ì¤‘ì¹˜ ë¶€ì—¬||

- í™œì„±í™” í•¨ìˆ˜
    |ì´ë¦„|ê³µì‹|ì¶œë ¥ ë²”ìœ„
    |-|-|-|
    |Sigmoid|$\phi = \frac{1}{1+e^{-x}}$|0 ~ 1|
    |tanh|$\tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}$|-1 ~ 1|
    |ReLU|$f(z) = max(0, z)$|$0 \leq f(x)$|
    |Leaky ReLU|$f(z) = max(\epsilon z, z)$|$0 \leq f(x)$|
    |ELU|$f(x) = x \space \text{if } x \geq 0$<br>$f(x) = \alpha (e^x - 1) \space \text{if } x < 0$|$0 \leq f(x)$|
    |SoftPlus|$f(z) =  \ln(1 + e^x)$|$0 \leq f(x)$|
    |GeLU|$0.5 \cdot x \cdot \left( 1 + \tanh \left( \sqrt{\frac{2}{\pi}} \cdot \left( x + 0.044715 \cdot x^3 \right) \right) \right)$|Free <br>ReLU ê³„ì—´ ê·¸ë˜í”„ì™€ ë¹„ìŠ·|

- ì˜µí‹° ë§ˆì´ì €
    : ìˆ˜ì¹˜ ìµœì í™” ì•Œê³ ë¦¬ì¦˜
    |ì´ë¦„|í•™ìŠµë¥ |íƒìƒ‰ ë°©í–¥|ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜|
    |-|-|-|-|
    |SGD|ìƒìˆ˜|ê¸°ìš¸ê¸°|íƒìƒ‰ ë°©í–¥
    |Momentum|ìƒìˆ˜|ë‹¨ê¸° ëˆ„ì  ê¸°ìš¸ê¸°|íƒìƒ‰ ë°©í–¥
    |AdaGrad|ì¥ê¸° íŒŒë¼ë¯¸í„° ë³€í™”ëŸ‰ê³¼ ë°˜ë¹„ë¡€|ê¸°ìš¸ê¸°|í•™ìŠµ ë¥ 
    |RMSProp|ë‹¨ê¸° íŒŒë¼ë¯¸í„° ë³€í™”ëŸ‰ê³¼ ë°˜ë¹„ë¡€|ê¸°ìš¸ê¸°|í•™ìŠµ ë¥ 
    |Adam|ë‹¨ê¸° íŒŒë¼ë¯¸í„° ë³€í™”ëŸ‰ê³¼ ë°˜ë¹„ë¡€|ë‹¨ê¸° ëˆ„ì  Grad|í•™ìŠµ ë¥ 

- ë¬¸ì œ ë° ì™„í™”ë²•
    - ê²½ì‚¬ ì†Œì‹¤ ë¬¸ì œ
        - ReLU ê³„ì—´ì˜ í™œì„±í™” í•¨ìˆ˜ ì‚¬ìš© <br> (Dead ReLU ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆìŒ)
    - ê³¼ì í•© ë¬¸ì œ
        |ì´ë¦„|ë‚´ìš©|
        |-|-|
        |L1 ê·œì œ|ê°€ì¤‘ì¹˜ì˜ ì ˆëŒ€ê°’ê³¼ ë¹„ë¡€í•˜ëŠ” ë¹„ìš© ì¶”ê°€<br>ê°€ì¤‘ì¹˜ë¥¼ 0ìœ¼ë¡œ ë§Œë“¤ì–´ íŠ¹ì„±ì— ëŒ€í•œ ì˜í–¥ ì œê±°<br>(ëª¨ë¸ì˜ í¬ì†Œì„± ì¦ê°€)|
        |L2 ê·œì œ|ê°€ì¤‘ì¹˜ì˜ ì œê³±ì— ë¹„ë¡€í•˜ëŠ” ë¹„ìš© ì¶”ê°€<br>ê°€ì¤‘ì¹˜ì˜ ê°’ì„ ì¤„ì—¬ ë³µì¡ì„±ì„ ë‚®ì¶˜ë‹¤<br>(ê°€ì¤‘ì¹˜ê°€ ë„ˆë¬´ ì»¤ì§€ëŠ” ê²ƒì„ ë°©ì§€)<br>|
        |ë“œë¡­ ì•„ì›ƒ|í•™ìŠµ ê³¼ì • ì¤‘ ë…¸ë“œë¥¼ ì„ì˜ë¡œ ë¹„í™œì„±|
        |Early Stop|ë” ì´ìƒ í•™ìŠµì´ ì§„í–‰ë˜ì§€ ì•Šì„ë–„ í•™ìŠµ ì¤‘ë‹¨|
        |ë°ì´í„° ì¦ê°•|ë¹„ìŠ·í•œ ë°ì´í„°ë¥¼ ë³µì œí•˜ì—¬ í•™ìŠµ ë°ì´í„°ë¡œ ë§Œë“¬<br>í…ŒìŠ¤íŠ¸ í• ë–„ ì¦ê°• ê¸ˆì§€|

- ë°ì´í„° ì¦ê°• ê¸°ë²•
    - keras ë³€í˜• ì¦ê°• : ì¼€ë¼ìŠ¤ ë‚´ì¥ ìœ¼ë¡œ ê°ë„ ì¡°ì ˆ ë° í¬ê¸° ë°˜ì „ë“±ì„ ì´ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ ì¦ê°•
    - Auto Encoder ì¦ê°• : Auto Encoder ë¡œ ìƒì„±ëœ ë°ì´í„°ë¥¼ ì´ìš©í•œ ì¦ê°•

- ë‹¤ì–‘í•œ Pretraind ëª¨ë¸
    - CNN ê¸°ë°˜
        |ì´ë¦„|ë‚´ìš©|íŠ¹ì§•|ë ˆì´ì–´|
        |-|-|-|-|
        |LeNet|CNN ì´ˆê¸° ëª¨ë¸|ì–€ ë¥´ì¿¤ì— ì˜í•´ ê°œë°œ, ì†ê¸€ì”¨ ì¸ì‹ì— ì‚¬ìš©|ê¸°ë³¸ CNN êµ¬ì¡° (Convolutional Layers, Pooling Layers)|
        |AlexNet|ReLU í™œì„±í™” í•¨ìˆ˜, ë°ì´í„° ì¦ê°•, MaxPoolingì„ í†µí•œ ë²¡í„°í™”, ë“œë¡­ì•„ì›ƒ, ë‹¤ì¤‘ GPU í™œìš©|ReLU í™œìš©, ë°ì´í„° ì¦ê°•ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ|Convolutional Layers, ReLU, MaxPooling, Dropout|
        |VGG-16|3x3 í•„í„°ì™€ 2x2 MaxPooling í™œìš©, êµ¬ì¡° ë‹¨ìˆœí™”, ê·œì œ ê¸°ë²• ì ìš©|ì˜¥ìŠ¤í¬ë“œ VGG ê·¸ë£¹ì— ì˜í•´ ê°œë°œ, ê¹Šì´ ìˆëŠ” ë„¤íŠ¸ì›Œí¬|Convolutional Layers (3x3), MaxPooling (2x2), Fully Connected Layers|
        |InceptionNet<br>(Google Net)|Bottle neck êµ¬ì¡°, Inception Module, Auxiliary classifier, Main classifier|Googleì— ì˜í•´ ê°œë°œ, 1x1 í•„í„°ë¡œ íŒŒë¼ë¯¸í„° ìˆ˜ ê°ì†Œ|Inception Modules, 1x1, 3x3, 5x5 Convolutions, Pooling|
        |ResNet|Residual blockì„ í†µí•œ Skip Connection, ê²½ì‚¬ ì†Œì‹¤ ë¬¸ì œ ì™„í™”|Microsoftì— ì˜í•´ ê°œë°œ, VGG-19ì˜ ë¼ˆëŒ€, Residual Blocks ì‚¬ìš©|Residual Blocks, Skip Connections, Convolutional Layers|
        |MobileNet|Depthwise Separable Convolution, ê° ì±„ë„ë³„ë¡œ ë…ë¦½ì ì¸ ì—°ì‚° í›„ í†µí•©|Googleì˜ Howardì— ì˜í•´ ê°œë°œ, ì„±ëŠ¥ ìœ ì§€ ë° ì†ë„ í–¥ìƒ|Depthwise Separable Convolutions, 1x1 Convolutions|
        |DenseNet|Dense Block êµ¬ì¡°, ëª¨ë“  ë ˆì´ì–´ì˜ inputì„ outputì— Concat|ResNetê³¼ ë¹„ìŠ·í•œ ì„±ëŠ¥, Feature ì¬ì‚¬ìš© ì¦ê°€|Dense Blocks, Convolutional Layers, Concatenation|
        |EfficientNet|ìµœì ì˜ Depth, Width, Resolutionì„ ì°¾ê¸° ìœ„í•œ Grid Search, íš¨ìœ¨ì ì¸ ëª¨ë¸ í¬ê¸° ë° ì„±ëŠ¥|êµ¬ê¸€ì— ì˜í•´ ê°œë°œ, ëª¨ë¸ í¬ê¸°ì™€ ê³„ì‚° íš¨ìœ¨ì„± ìµœì í™”|Compound Scaling, Convolutional Layers, EfficientNet Blocks|

    - ìì—°ì–´ ì²˜ë¦¬ ê¸°ë°˜
        |ì´ë¦„|ë‚´ìš©|íŠ¹ì§•|
        |-|-|-|
        |Transformer|Attention ë©”ì»¤ë‹ˆì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ì…ë ¥ ì‹œí€€ìŠ¤ì˜ ëª¨ë“  ìš”ì†Œë¥¼ ë™ì‹œì ìœ¼ë¡œ ì²˜ë¦¬í•˜ë©°, ì¥ê¸° ì˜ì¡´ì„± ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ëª¨ë¸|Self-Attention, Multi-Head Attention, Encoder-Decoder êµ¬ì¡°|
        |BERT (Bidirectional Encoder Representations from Transformers)|ì–‘ë°©í–¥ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ìì—°ì–´ ì´í•´ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¨ ëª¨ë¸. Masked Language Modelingê³¼ Next Sentence Predictionì„ í†µí•´ ì‚¬ì „ í•™ìŠµë¨|Bidirectional Context, Pre-training and Fine-tuning, ë‹¤ì–‘í•œ NLP ì‘ì—…ì— í™œìš©|
        |GPT (Generative Pre-trained Transformer)|ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ë¡œ, ì–¸ì–´ ìƒì„±ê³¼ ë²ˆì—­ì„ í¬í•¨í•œ ë‹¤ì–‘í•œ NLP ì‘ì—…ì— ê°•ë ¥í•œ ì„±ëŠ¥ì„ ë°œíœ˜. Transformer ê¸°ë°˜ìœ¼ë¡œ ëŒ€ê·œëª¨ ë°ì´í„°ì—ì„œ ì‚¬ì „ í•™ìŠµë¨|Unidirectional Context, Language Modeling, Transfer Learning|



    - ê°ì²´ íƒì§€ ëª¨ë¸
        |Shots|ì´ë¦„|ë‚´ìš©|íŠ¹ì§•|
        |-|-|-|-|
        |Two|R-CNN<br>(Regions with CNN features)|ì „í†µì ì¸ ê°ì²´ íƒì§€ ë°©ë²•:<br>Selective Searchë¡œ ì˜ì—­ì„ ì œì•ˆ-><br>CNNìœ¼ë¡œ í”¼ì²˜ ë²¡í„°ë¡œ ë³€í™˜-><br>ë¶„ë¥˜ ë° ê²½ê³„ ìƒìë¥¼ ì˜ˆì¸¡|Two-stage detector,<br>Selective Search,<br>CNN-based feature extraction|
        |Two|Fast R-CNN|R-CNNì˜ ê°œì„ , ì „ì²´ ì´ë¯¸ì§€ì— ëŒ€í•´ CNNì„ í•œ ë²ˆë§Œ ì‹¤í–‰,<br>RoI Poolingë¡œ ê° ì œì•ˆ ì˜ì—­ì˜ í”¼ì²˜ë¥¼ ì¶”ì¶œ ë¶„ë¥˜ ë° íšŒê·€|RoI Pooling,<br>End-to-end training,<br>Faster processing compared to R-CNN|
        |Two|Faster R-CNN|Region Proposal Network (RPN)ê³¼<br>Fast R-CNNì„ ê²°í•©|RPN for region proposals,<br>ROI Pooling|
        |One|YOLO<br>(You Only Look Once)|One-Shot. ë¹ ë¥¸ ì†ë„ì™€ ë†’ì€ ì‹¤ì‹œê°„ ì„±ëŠ¥|Bounding box regression,<br>Class prediction|
        |One|SSD<br>(Single Shot MultiBox Detector)|ë‹¤ì–‘í•œ í¬ê¸° ê°ì²´ë¥¼ íƒì§€<br>ë‹¤ì–‘í•œ ìŠ¤ì¼€ì¼ì˜ íŠ¹ì„±ì„ í™œìš©|Multi-scale feature maps,<br>Default boxes|

        > RoI : Region of interest


### ëª¨ë¸ í‰ê°€
  
  1. ì •í™•ë„(Accuracy):
      - ì¼ë°˜ì  í‰ê°€ ì§€í‘œ
      - ë°ì´í„°ê°€ ê· í˜•ì  ì¼ë•Œ
  
  2. ì¬í˜„ìœ¨(Recall), ì •ë°€ë„(Precision), F1-score:
      - ë°ì´í„°ì˜ ë¶ˆê· í˜• 30% ì´ìƒì¼ë•Œ
      - ì¬í˜„ìœ¨: ì‹¤ì œ ì–‘ì„± ì¤‘ ì–‘ì„± ë¹„ìœ¨ <br>
         : $$\frac{\text{TP}}{\text{FP} + {\text{FP}}}$$
      - ì •ë°€ë„: ì˜ˆì¸¡í•œ ì–‘ì„± ì¤‘ ì‹¤ì œ ì–‘ì„±ë¹„ìœ¨ <br>
         : $$\frac{\text{TP}}{\text{FP} + {\text{FN}}}$$
      - F1-score: ì¬í˜„ìœ¨ê³¼ ì •ë°€ë„ì˜ ì¡°í™” í‰ê· 
  
  3. í˜¼ë™ í–‰ë ¬(Confusion Matrix):
      - ì‹¤ì œ ê°’ê³¼ ì˜ˆì¸¡ ê°’ì˜ ê´€ê³„ë¥¼ ë³´ì—¬ì¤Œ
      - ì •í™•ë„, ì¬í˜„ìœ¨, ì •ë°€ë„ ì§€í‘œ
      - ROC ê³¡ì„  ë° AUC(Area Under the Curve):
          - ì´ì§„ ë¶„ë¥˜ ì‹œ í‰ê°€ Metric
          - ì„ê³„ê°’ì— ë”°ë¥¸ True Positive Rateì™€ False Positive Rateë¥¼ ë‚˜íƒ€ëƒ„
          - AUC ê°’ì´ 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ì¢‹ìŒ, 0.5 ëŠ” ë„˜ì–´ì•¼ í•¨
          - AUC = 0.5 -> ëœë¤ ë¶„ë¥˜ê¸°ì™€ ì„±ëŠ¥ì´ ê°™ë‹¤.
  
  4. R-squared(R2-Score):
  
      - íšŒê·€ ëª¨ë¸ í‰ê°€ì— ì‚¬ìš©ë˜ëŠ” ì§€í‘œ
      - ëª¨ë¸ì´ ì¢…ì†ë³€ìˆ˜ì˜ ë³€ë™ì„ ì–¼ë§ˆë‚˜ ì˜ ì„¤ëª…í•˜ëŠ”ì§€ ë‚˜íƒ€ëƒ„
      - 0ì—ì„œ 1 ì‚¬ì´ì˜ ê°’ì„ ê°€ì§€ë©°, 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ëª¨ë¸ ì„±ëŠ¥ì´ ì¢‹ìŒ

  5. êµì°¨ ê²€ì¦(Cross-Validation):
  
      - kê°œì˜ í´ë“œ(fold)ë¡œ ë‚˜ëˆ„ì–´ ëª¨ë¸ì„ í‰ê°€
      - í›ˆë ¨ ,ê²€ì¦ ë°ì´í„°ë¥¼ ë¶„ë¦¬ í›„ ì¼ë°˜í™” ì„±ëŠ¥ í‰ê°€
      - ê³¼ì í•©ì„ ë°©ì§€í•˜ê³ , ì•ˆì •ì„±ì„ í™•ì¸
  
  
  
  6. ë„ë©”ì¸ ì§€ì‹ í™œìš©:
  
      - ë°ì´í„°ì— ëŒ€í•œ ë„ë©”ì¸ ì´í•´ ë° í‰ê°€

### ë¶„ë¥˜ ë¬¸ì œ
|ì´ë¦„|ë‚´ìš©|
|-|-|
|Mnist|ì† ê¸€ì”¨ ë¶„ë¥˜|
|CIFAR|ì‚¬ì§„ ëŒ€ìƒ ë¶„ë¥˜|
|í…ìŠ¤íŠ¸, í‘œì •, ê°ì„±|ì£¼ë¡œ ì‹œí€€ìŠ¤ context í•´ì„ ë¬¸ì œ|
|ì¼ ëŒ€ ë‹¤ ë¶„ë¥˜|ë‹¨ê³„ë³„ë¡œ í•˜ë‚˜ì”© ë¶„ë¥˜|

### íšŒê·€ ë¬¸ì œ
|ì´ë¦„|ë‚´ìš©|
|-|-|
|ì£¼íƒ ê°€ê²© ì˜ˆì¸¡|ê°€ê²© ì˜ˆì¸¡|
|ì£¼ì‹ ê°€ê²© ì˜ˆì¸¡|ê°€ê²© ì˜ˆì¸¡|
|ì˜¨ë„ ì˜ˆì¸¡|ê¸°ìƒ ë°ì´í„°ë¡œ ì˜¨ë„ ì˜ˆì¸¡|

### ì‹œê³„ì—´ ë°ì´í„°
- ì‹œê°„ ìˆœì„œì— ë”°ë¼ ë°œìƒí•˜ëŠ” ì—°ì†ì ì¸ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¯¸ë˜ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë°ì´í„°.

- ë‹¤ë³€ëŸ‰, ë‹¨ë³€ëŸ‰
    - **ë‹¤ë³€ëŸ‰ (Multivariate)**: ì—¬ëŸ¬ ì¢…ì† ë³€ìˆ˜(ì—¬ëŸ¬ ê°œì˜ ì •ë‹µ ë¼ë²¨).
    - **ë‹¤ë³€ìˆ˜ (Multivariable)**: ì—¬ëŸ¬ ë…ë¦½ ë³€ìˆ˜(ë‹¤ì–‘í•œ ì…ë ¥).
    - **ë‹¨ë³€ëŸ‰ (Univariate)**: ë‹¨ì¼ ì •ë‹µ ë¼ë²¨ì„ ê°€ì§€ëŠ” ë°ì´í„°.

- ì‹œê°„ì˜ ì¢…ì†ì„± (Time Dependence)
    - ê³¼ê±° ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¯¸ë˜ë¥¼ ì˜ˆì¸¡í•˜ëŠ” íŠ¹ì„±.
    - ë¶ˆê·œì¹™ì„±ì´ ìˆìœ¼ë©´ ì˜ˆì¸¡ì´ ì–´ë ¤ì›Œì§.

- ì‹œê³„ì—´ ì¢…ì†ì„± (Serial Dependence)
    - ì‹œê³„ì—´ ë°ì´í„°ê°€ ì´ì „ ê°’ì— ì˜ì¡´í•˜ëŠ” íŒ¨í„´. ì´ì „ ë°ì´í„°ê°€ í˜„ì¬ì™€ ë¯¸ë˜ì˜ ë°ì´í„°ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ê²½ìš°ë¥¼ ì„¤ëª…í•¨.

- Cycles
    - ë°ì´í„°ê°€ ì£¼ê¸°ì ìœ¼ë¡œ ë°˜ë³µë˜ëŠ” í˜„ìƒì„ ì„¤ëª…. ë°˜ë“œì‹œ ì‹œê°„ì— ë”°ë¼ ë°˜ë³µë˜ì§€ ì•Šì•„ë„ ë˜ë©°, ìì—°ìŠ¤ëŸ½ê²Œ ë°˜ë³µë˜ëŠ” í˜„ìƒ.

- ì‹œê³„ì—´ ë°ì´í„°ì˜ ì£¼ìš” íŠ¹ì„±
    - **ê³„ì ˆì„± (Seasonality)**: ì¼ì¼, ì£¼ê°„, ì—°ê°„ ë“± ì£¼ê¸°ì ìœ¼ë¡œ ë³€í™”í•˜ëŠ” íŒ¨í„´.
    - **ì¶”ì„¸ (Trend)**: ì¥ê¸°ì ì¸ ë³€í™” ê²½í–¥ì„ ë‚˜íƒ€ëƒ„. ì´ë™ í‰ê·  í”Œë¡¯ì„ í†µí•´ ì¶”ì„¸ë¥¼ ì‹œê°í™”í•  ìˆ˜ ìˆìŒ.

- ë‹¤í•­ íŠ¹ì„± (Polynomial Features)
    - ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ë‹¤í•­ì‹ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ìˆìŒ. ì˜ˆë¥¼ ë“¤ì–´, $degree$ê°€ 1ì¼ ë•Œ, 2ì¼ ë•Œ, nì¼ ë•Œì˜ ë‹¤í•­ì‹ ëª¨ë¸ì´ ê°ê° ìˆìŒ.
        - $y = w \times time + b$ (ì¼ì°¨ì‹)
        - $y = w_0 \times time^2 + w_1 \times time + b$ (ì´ì°¨ì‹)
        - ë‹¤í•­ì‹ ëª¨ë¸ë¡œ ì˜ˆì¸¡ ê°€ëŠ¥.

- ì •ìƒì„± (Stationarity)
    - ì‹œê³„ì—´ ë¶„ì„ì´ ìš©ì´í•˜ë ¤ë©´ ë°ì´í„°ê°€ ì •ìƒì„±ì„ ê°€ì ¸ì•¼ í•¨.
    - **ì •ìƒì„± íŒë‹¨ ê¸°ì¤€**:
        - ì‹œê°ì ìœ¼ë¡œ: ìƒìŠ¹ ë˜ëŠ” í•˜ë½ì´ ì§€ì†ë˜ì§€ ì•ŠìŒ, ë³€ë™í­ ì¼ì •.
        - í†µê³„ì ìœ¼ë¡œ: í‰ê· ê³¼ ë¶„ì‚°ì´ ì¼ì •í•˜ë©°, ê³µë¶„ì‚°ì´ ì‹œê°„ê³¼ ë¬´ê´€í•˜ê²Œ ìœ ì§€ë¨.

    - **ë¹„ì •ìƒì  ë°ì´í„°**ëŠ” ë³€í™˜ì„ í†µí•´ ì •ìƒì„±ì„ ê°€ì§€ê²Œ í•œ í›„ ë¶„ì„ì„ ì§„í–‰í•´ì•¼ í•¨.

> ì‹œê³„ì—´ â†’ ì •ìƒì„± ê²€ì¦ â†’ ì •ìƒì„±ì„ ë„ë„ë¡ ë³€í™˜ â†’ ì •í™•ë„ í–¥ìƒ

### ì°¸ê³  ë§í¬
- [roboflow](https://roboflow.com/) <br>
- [ultraytics](https://docs.ultralytics.com/integrations/roboflow/) <br>
- [Learn open cv](https://learnopencv.com/)  <br>
- [supervisely](https://supervisely.com/) <br>
- [superb ai](https://superb-ai.com/ko) <br>
- [label studio](https://labelstud.io/) -> ì˜¤ë””ì˜¤ì—ì„œ ê°ì„± ë¶„ì„ ê°€ëŠ¥ <br>

- segmentation tool
    - [Label Studio](https://labelstud.io/guide/) <br>
    - [Label Me](https://github.com/labelmeai/labelme) <br>
    - [Anylabeling](https://github.com/vietanhdev/anylabeling) <br>
    - [X-Anylabeling](https://github.com/CVHub520/X-AnyLabeling) <br>